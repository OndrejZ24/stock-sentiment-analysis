{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8672ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitek\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c351b1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (13663, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment_ready_text</th>\n",
       "      <th>type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>mentioned_tickers</th>\n",
       "      <th>n_tickers</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1hqr72t</td>\n",
       "      <td>good roe return equity quick data analysis s s...</td>\n",
       "      <td>post</td>\n",
       "      <td>investing</td>\n",
       "      <td>2024-12-31 23:56:46</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>TOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1072</td>\n",
       "      <td>171</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1hqqmq2</td>\n",
       "      <td>soundhound soun market cap 75x s annualized re...</td>\n",
       "      <td>post</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2024-12-31 23:24:29</td>\n",
       "      <td>0.039443</td>\n",
       "      <td>SOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>476</td>\n",
       "      <td>82</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1hqqgv5</td>\n",
       "      <td>smci beginning play p e looking low current va...</td>\n",
       "      <td>post</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2024-12-31 23:15:10</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>SMCI</td>\n",
       "      <td>1</td>\n",
       "      <td>419</td>\n",
       "      <td>75</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1hqpxkb</td>\n",
       "      <td>thoughts rddt feedback appreciated</td>\n",
       "      <td>post</td>\n",
       "      <td>investing</td>\n",
       "      <td>2024-12-31 22:45:36</td>\n",
       "      <td>0.018076</td>\n",
       "      <td>RDDT</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1hqpw3r</td>\n",
       "      <td>d r horton dhi good value stock 7 ytd forward ...</td>\n",
       "      <td>post</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>2024-12-31 22:43:25</td>\n",
       "      <td>0.051121</td>\n",
       "      <td>DHI</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>75</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                               sentiment_ready_text  type  \\\n",
       "0  1hqr72t  good roe return equity quick data analysis s s...  post   \n",
       "1  1hqqmq2  soundhound soun market cap 75x s annualized re...  post   \n",
       "2  1hqqgv5  smci beginning play p e looking low current va...  post   \n",
       "3  1hqpxkb                 thoughts rddt feedback appreciated  post   \n",
       "4  1hqpw3r  d r horton dhi good value stock 7 ytd forward ...  post   \n",
       "\n",
       "        subreddit          created_utc  normalized_score mentioned_tickers  \\\n",
       "0       investing  2024-12-31 23:56:46          0.019045               TOP   \n",
       "1          stocks  2024-12-31 23:24:29          0.039443              SOUN   \n",
       "2          stocks  2024-12-31 23:15:10          0.011074              SMCI   \n",
       "3       investing  2024-12-31 22:45:36          0.018076              RDDT   \n",
       "4  ValueInvesting  2024-12-31 22:43:25          0.051121               DHI   \n",
       "\n",
       "   n_tickers  text_length  word_count        date  hour  day_of_week  \n",
       "0          1         1072         171  2024-12-31    23            1  \n",
       "1          1          476          82  2024-12-31    23            1  \n",
       "2          1          419          75  2024-12-31    23            1  \n",
       "3          1           42           6  2024-12-31    22            1  \n",
       "4          1          391          75  2024-12-31    22            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Config ===\n",
    "DATA_PATH_IN  = \"preprocessed_data.csv\"\n",
    "DATA_PATH_OUT = \"finbert_sentiment.csv\" \n",
    "\n",
    "ID_COL        = \"id\"\n",
    "TEXT_COL      = \"sentiment_ready_text\"\n",
    "\n",
    "# === Load data ===\n",
    "df = pd.read_csv(DATA_PATH_IN)\n",
    "\n",
    "print(\"Input shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0167a0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitek\\AppData\\Roaming\\Python\\Python313\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# === Load FinBERT model ==\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(\"Using device:\", \"GPU\" if device == 0 else \"CPU\")\n",
    "\n",
    "# === Build sentiment pipeline ===\n",
    "sentiment_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    return_all_scores=True,\n",
    "    truncation=True,\n",
    "    max_length=128            # can increase to 256 if your texts are longer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411ba335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_texts(texts):\n",
    "    \"\"\"\n",
    "    Run FinBERT on a list of texts and return structured sentiment info.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The input texts to classify.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : list of dict\n",
    "        Each dict has:\n",
    "        - sentiment_label : str       ('positive', 'neutral', 'negative')\n",
    "        - sentiment_score : float     (p_pos - p_neg in [-1, 1])\n",
    "        - p_pos, p_neu, p_neg : float (probabilities)\n",
    "    \"\"\"\n",
    "    # This calls the HF pipeline once for the whole batch\n",
    "    outputs = sentiment_pipe(texts)\n",
    "\n",
    "    results = []\n",
    "    for out in outputs:\n",
    "        # out is a list like:\n",
    "        # [{'label': 'positive', 'score': 0.7}, {'label': 'neutral', 'score': 0.2}, {'label': 'negative', 'score': 0.1}]\n",
    "        # Normalize label names to lowercase to be robust to variations\n",
    "        probs = {d[\"label\"].lower(): float(d[\"score\"]) for d in out}\n",
    "\n",
    "        p_pos = probs.get(\"positive\", 0.0)\n",
    "        p_neg = probs.get(\"negative\", 0.0)\n",
    "        p_neu = probs.get(\"neutral\", 0.0)\n",
    "\n",
    "        # Continuous sentiment score in [-1, 1]\n",
    "        sentiment_score = p_pos - p_neg\n",
    "\n",
    "        # Discrete label = argmax over the three probabilities\n",
    "        sentiment_label = max(probs, key=probs.get)\n",
    "\n",
    "        results.append({\n",
    "            \"sentiment_label\": sentiment_label,\n",
    "            \"sentiment_score\": sentiment_score,\n",
    "            \"p_pos\": p_pos,\n",
    "            \"p_neu\": p_neu,\n",
    "            \"p_neg\": p_neg\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa2b650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts to process: 13663\n",
      "Processed 32 / 13663 texts\n",
      "Processed 1632 / 13663 texts\n",
      "Processed 3232 / 13663 texts\n",
      "Processed 4832 / 13663 texts\n",
      "Processed 6432 / 13663 texts\n",
      "Processed 8032 / 13663 texts\n",
      "Processed 9632 / 13663 texts\n",
      "Processed 11232 / 13663 texts\n",
      "Processed 12832 / 13663 texts\n",
      "Scores computed: 13663 rows in df: 13663\n"
     ]
    }
   ],
   "source": [
    "# === Batch configuration ===\n",
    "# batch size kdyztak budeme menit \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "sentiment_labels = []\n",
    "sentiment_scores = []\n",
    "p_pos_list = []\n",
    "p_neu_list = []\n",
    "p_neg_list = []\n",
    "\n",
    "# Replace NA with empty strings so the model doesn't crash\n",
    "texts = df[TEXT_COL].fillna(\"\").tolist()\n",
    "\n",
    "n_texts = len(texts)\n",
    "print(\"Number of texts to process:\", n_texts)\n",
    "\n",
    "for start in range(0, n_texts, BATCH_SIZE):\n",
    "    end = start + BATCH_SIZE\n",
    "    batch = texts[start:end]\n",
    "\n",
    "    scored = score_texts(batch)\n",
    "\n",
    "    # Extend our result lists\n",
    "    for r in scored:\n",
    "        sentiment_labels.append(r[\"sentiment_label\"])\n",
    "        sentiment_scores.append(r[\"sentiment_score\"])\n",
    "        p_pos_list.append(r[\"p_pos\"])\n",
    "        p_neu_list.append(r[\"p_neu\"])\n",
    "        p_neg_list.append(r[\"p_neg\"])\n",
    "\n",
    "    # progress print\n",
    "    if (start // BATCH_SIZE) % 50 == 0:\n",
    "        print(f\"Processed {min(end, n_texts)} / {n_texts} texts\")\n",
    "\n",
    "print(\"Scores computed:\", len(sentiment_labels), \"rows in df:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68572e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FinBERT sentiment data to: finbert_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# Optional: save to disk\n",
    "df.to_csv(DATA_PATH_OUT, index=False)\n",
    "print(\"Saved FinBERT sentiment data to:\", DATA_PATH_OUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
