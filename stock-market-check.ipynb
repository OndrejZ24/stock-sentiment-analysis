{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6e50fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils:spaCy model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from utils import get_oracle_connection, fetch_historical_prices, check_market_moved_before_date, adjust_to_trading_day\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eacddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle connection successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/33/r5z8ht2928103xc7s_sb_xx80000gq/T/ipykernel_4226/3556954890.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "conn = get_oracle_connection()\n",
    "\n",
    "if not conn:\n",
    "    raise ConnectionError(\"Failed to establish a connection to the Oracle database.\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM sentiment_signals\n",
    "ORDER BY ticker\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632199f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing signals:  20%|█▉        | 907/4604 [00:09<00:56, 64.94it/s] ERROR:yfinance:$BRK.A: possibly delisted; no timezone found\n",
      "Processing signals:  20%|█▉        | 915/4604 [00:10<01:38, 37.28it/s]ERROR:yfinance:$BRK.A: possibly delisted; no timezone found\n",
      "Processing signals:  20%|█▉        | 915/4604 [00:10<01:38, 37.28it/s]ERROR:yfinance:$BRK.B: possibly delisted; no timezone found\n",
      "ERROR:yfinance:$BRK.B: possibly delisted; no timezone found\n",
      "Processing signals:  25%|██▍       | 1150/4604 [00:15<01:01, 56.21it/s]ERROR:yfinance:$COLA: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "Processing signals:  25%|██▌       | 1158/4604 [00:15<01:18, 44.12it/s]ERROR:yfinance:$COLA: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "Processing signals:  83%|████████▎ | 3808/4604 [00:52<00:22, 34.70it/s] ERROR:yfinance:$SI: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "Processing signals:  83%|████████▎ | 3816/4604 [00:52<00:29, 26.54it/s]ERROR:yfinance:$SI: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "Processing signals:  83%|████████▎ | 3827/4604 [00:52<00:28, 27.51it/s]ERROR:yfinance:$SMA: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "Processing signals:  83%|████████▎ | 3831/4604 [00:53<00:37, 20.63it/s]ERROR:yfinance:$SMA: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "Processing signals:  95%|█████████▍| 4369/4604 [01:00<00:03, 72.93it/s] ERROR:yfinance:$VG: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "ERROR:yfinance:$VG: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "Processing signals:  99%|█████████▉| 4565/4604 [01:03<00:00, 103.03it/s]ERROR:yfinance:$WOLF: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "ERROR:yfinance:$WOLF: possibly delisted; no price data found  (1d 2024-01-01 -> 2024-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1704085200, endDate = 1735621200\")\n",
      "Processing signals: 100%|██████████| 4604/4604 [01:04<00:00, 71.09it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original signals: 4604\n",
      "Filtered signals (market didn't move): 1810\n",
      "Failed tickers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process signals and filter out those where market already moved\n",
    "filtered_signals = []\n",
    "current_ticker = None\n",
    "price_data = None\n",
    "failed_tickers = set()\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing signals\"):\n",
    "    ticker = row['TICKER']\n",
    "    signal_date = adjust_to_trading_day(str(row['SIGNAL_DATE'])[:10])\n",
    "\n",
    "    # Fetch new price data only when ticker changes\n",
    "    if ticker != current_ticker:\n",
    "        current_ticker = ticker\n",
    "        if ticker in failed_tickers:\n",
    "            price_data = None\n",
    "        else:\n",
    "            try:\n",
    "                price_data = fetch_historical_prices(ticker, \"2024-01-01\", \"2024-12-31\")\n",
    "            except Exception:\n",
    "                failed_tickers.add(ticker)\n",
    "                price_data = None\n",
    "\n",
    "    # Skip if no price data available\n",
    "    if price_data is None or price_data.empty:\n",
    "        continue\n",
    "\n",
    "    # Check if market moved before this signal date\n",
    "    result = check_market_moved_before_date(price_data, signal_date)\n",
    "\n",
    "    # If result is None or market did NOT move, keep the signal\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    if not result['market_moved_flag']:\n",
    "        # Market didn't move - this is a valid signal to keep\n",
    "        signal_row = row.to_dict()\n",
    "        signal_row.update(result)\n",
    "        filtered_signals.append(signal_row)\n",
    "\n",
    "# Create final dataframe with filtered signals\n",
    "df_filtered = pd.DataFrame(filtered_signals)\n",
    "print(f\"\\nOriginal signals: {len(df)}\")\n",
    "print(f\"Filtered signals (market didn't move): {len(df_filtered)}\")\n",
    "print(f\"Failed tickers: {len(failed_tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ce2c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle connection successful!\n",
      "============================================================\n",
      "APPLYING QUALITY GATES BEFORE EXPORT\n",
      "============================================================\n",
      "Gate 1 (valid SIGNAL_DATE): Removed 0 rows with null dates\n",
      "Gate 2 (window_mentions >= 5): Removed 0 rows with insufficient mentions\n",
      "Gate 3 (valid Z_SCORE): Removed 0 rows with null/inf z-score\n",
      "Gate 4 (valid SIGNAL_TYPE): Removed 0 rows with invalid signal type\n",
      "Gate 5 (no duplicates): Removed 0 duplicate (ticker, date, type) combinations\n",
      "\n",
      "✓ QUALITY GATES COMPLETE: 1810/1810 signals passed (0 removed)\n",
      "============================================================\n",
      "Created filtered_signals table with baseline metrics\n",
      "Exported 1810 rows to Oracle table filtered_signals\n",
      "\n",
      "Signal type distribution in exported data:\n",
      "SIGNAL_TYPE\n",
      "SELL    1018\n",
      "BUY      792\n",
      "\n",
      "Signal direction distribution:\n",
      "SIGNAL_DIRECTION\n",
      "-1    1018\n",
      " 1     792\n",
      "Exported 1810 rows to Oracle table filtered_signals\n",
      "\n",
      "Signal type distribution in exported data:\n",
      "SIGNAL_TYPE\n",
      "SELL    1018\n",
      "BUY      792\n",
      "\n",
      "Signal direction distribution:\n",
      "SIGNAL_DIRECTION\n",
      "-1    1018\n",
      " 1     792\n"
     ]
    }
   ],
   "source": [
    "# Export filtered signals to Oracle with quality gates\n",
    "conn = get_oracle_connection()\n",
    "\n",
    "if conn:\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # =========================================================================\n",
    "    # QUALITY GATES - Validate data before export\n",
    "    # =========================================================================\n",
    "    print(\"=\" * 60)\n",
    "    print(\"APPLYING QUALITY GATES BEFORE EXPORT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    initial_count = len(df_filtered)\n",
    "\n",
    "    # Gate 1: Remove rows with null/invalid SIGNAL_DATE\n",
    "    df_export = df_filtered[df_filtered['SIGNAL_DATE'].notna()].copy()\n",
    "    gate1_removed = initial_count - len(df_export)\n",
    "    print(f\"Gate 1 (valid SIGNAL_DATE): Removed {gate1_removed} rows with null dates\")\n",
    "\n",
    "    # Gate 2: Ensure WINDOW_MENTIONS >= MIN_MENTIONS (5 is the threshold)\n",
    "    MIN_MENTIONS_THRESHOLD = 5\n",
    "    before_gate2 = len(df_export)\n",
    "    df_export = df_export[df_export['WINDOW_MENTIONS'] >= MIN_MENTIONS_THRESHOLD]\n",
    "    gate2_removed = before_gate2 - len(df_export)\n",
    "    print(f\"Gate 2 (window_mentions >= {MIN_MENTIONS_THRESHOLD}): Removed {gate2_removed} rows with insufficient mentions\")\n",
    "\n",
    "    # Gate 3: Ensure Z_SCORE is valid (not null, not inf)\n",
    "    before_gate3 = len(df_export)\n",
    "    df_export = df_export[\n",
    "        df_export['Z_SCORE'].notna() &\n",
    "        ~np.isinf(df_export['Z_SCORE'].astype(float))\n",
    "    ]\n",
    "    gate3_removed = before_gate3 - len(df_export)\n",
    "    print(f\"Gate 3 (valid Z_SCORE): Removed {gate3_removed} rows with null/inf z-score\")\n",
    "\n",
    "    # Gate 4: Ensure SIGNAL_TYPE is BUY or SELL\n",
    "    before_gate4 = len(df_export)\n",
    "    df_export = df_export[df_export['SIGNAL_TYPE'].isin(['BUY', 'SELL'])]\n",
    "    gate4_removed = before_gate4 - len(df_export)\n",
    "    print(f\"Gate 4 (valid SIGNAL_TYPE): Removed {gate4_removed} rows with invalid signal type\")\n",
    "\n",
    "    # Gate 5: Remove duplicates (ticker, signal_date, signal_type)\n",
    "    before_gate5 = len(df_export)\n",
    "    df_export = df_export.drop_duplicates(subset=['TICKER', 'SIGNAL_DATE', 'SIGNAL_TYPE'], keep='first')\n",
    "    gate5_removed = before_gate5 - len(df_export)\n",
    "    print(f\"Gate 5 (no duplicates): Removed {gate5_removed} duplicate (ticker, date, type) combinations\")\n",
    "\n",
    "    total_removed = initial_count - len(df_export)\n",
    "    print(f\"\\n✓ QUALITY GATES COMPLETE: {len(df_export)}/{initial_count} signals passed ({total_removed} removed)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Drop and recreate table with correct structure\n",
    "    try:\n",
    "        cursor.execute(\"DROP TABLE filtered_signals\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Create table with ALL necessary columns (including baseline metrics for demo app)\n",
    "    create_sql = \"\"\"\n",
    "    CREATE TABLE filtered_signals (\n",
    "        TICKER VARCHAR2(20),\n",
    "        SIGNAL_DATE DATE,\n",
    "        SIGNAL_TYPE VARCHAR2(10),\n",
    "        SIGNAL_DIRECTION NUMBER(3,0),\n",
    "        SENTIMENT_MEAN NUMBER(15,6),\n",
    "        WINDOW_SENTIMENT NUMBER(15,6),\n",
    "        WINDOW_MENTIONS NUMBER(15,2),\n",
    "        BASELINE_MEAN NUMBER(15,6),\n",
    "        BASELINE_STD NUMBER(15,6),\n",
    "        Z_SCORE NUMBER(15,6),\n",
    "        SIGNAL_SCORE NUMBER(15,6),\n",
    "        TOTAL_UPVOTES NUMBER(15,6),\n",
    "        TARGET_DATE VARCHAR2(20),\n",
    "        PCT_CHANGE_3D NUMBER(15,6),\n",
    "        PCT_3D_Z NUMBER(15,6),\n",
    "        RET_Z NUMBER(15,6),\n",
    "        VOL_Z NUMBER(15,6),\n",
    "        VOL_EXPANSION NUMBER(15,6),\n",
    "        ATR_14 NUMBER(15,6),\n",
    "        ATR_MOVE NUMBER(15,6),\n",
    "        MARKET_MOVED_FLAG NUMBER(1,0)\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.execute(create_sql)\n",
    "    print(\"Created filtered_signals table with baseline metrics\")\n",
    "\n",
    "    # Updated insert statement with baseline columns\n",
    "    insert_sql = \"\"\"\n",
    "    INSERT INTO filtered_signals (\n",
    "        TICKER, SIGNAL_DATE, SIGNAL_TYPE, SIGNAL_DIRECTION, SENTIMENT_MEAN,\n",
    "        WINDOW_SENTIMENT, WINDOW_MENTIONS, BASELINE_MEAN, BASELINE_STD,\n",
    "        Z_SCORE, SIGNAL_SCORE, TOTAL_UPVOTES,\n",
    "        TARGET_DATE, PCT_CHANGE_3D, PCT_3D_Z, RET_Z, VOL_Z, VOL_EXPANSION,\n",
    "        ATR_14, ATR_MOVE, MARKET_MOVED_FLAG\n",
    "    ) VALUES (:1, :2, :3, :4, :5, :6, :7, :8, :9, :10, :11, :12, :13, :14, :15, :16, :17, :18, :19, :20, :21)\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare data with correct column mapping (including baseline metrics)\n",
    "    insert_data = []\n",
    "    for _, row in df_export.iterrows():\n",
    "        row_data = (\n",
    "            str(row.get('TICKER', '')),\n",
    "            pd.to_datetime(row.get('SIGNAL_DATE')).date() if pd.notna(row.get('SIGNAL_DATE')) else None,\n",
    "            str(row.get('SIGNAL_TYPE', '')),\n",
    "            int(row.get('SIGNAL_DIRECTION', 0)) if pd.notna(row.get('SIGNAL_DIRECTION')) else None,\n",
    "            float(row.get('SENTIMENT_MEAN', 0)) if pd.notna(row.get('SENTIMENT_MEAN')) else None,\n",
    "            float(row.get('WINDOW_SENTIMENT', 0)) if pd.notna(row.get('WINDOW_SENTIMENT')) else None,\n",
    "            float(row.get('WINDOW_MENTIONS', 0)) if pd.notna(row.get('WINDOW_MENTIONS')) else None,\n",
    "            float(row.get('BASELINE_MEAN', 0)) if pd.notna(row.get('BASELINE_MEAN')) else None,\n",
    "            float(row.get('BASELINE_STD', 0)) if pd.notna(row.get('BASELINE_STD')) else None,\n",
    "            float(row.get('Z_SCORE', 0)) if pd.notna(row.get('Z_SCORE')) else None,\n",
    "            float(row.get('SIGNAL_SCORE', 0)) if pd.notna(row.get('SIGNAL_SCORE')) else None,\n",
    "            float(row.get('TOTAL_UPVOTES', 0)) if pd.notna(row.get('TOTAL_UPVOTES')) else None,\n",
    "            str(row.get('target_date', '')) if pd.notna(row.get('target_date')) else None,\n",
    "            float(row.get('pct_change_3d', 0)) if pd.notna(row.get('pct_change_3d')) else None,\n",
    "            float(row.get('pct_3d_z', 0)) if pd.notna(row.get('pct_3d_z')) else None,\n",
    "            float(row.get('ret_z', 0)) if pd.notna(row.get('ret_z')) else None,\n",
    "            float(row.get('vol_z', 0)) if pd.notna(row.get('vol_z')) else None,\n",
    "            float(row.get('vol_expansion', 0)) if pd.notna(row.get('vol_expansion')) else None,\n",
    "            float(row.get('atr_14', 0)) if pd.notna(row.get('atr_14')) else None,\n",
    "            float(row.get('atr_move', 0)) if pd.notna(row.get('atr_move')) else None,\n",
    "            1 if row.get('market_moved_flag') else 0\n",
    "        )\n",
    "        insert_data.append(row_data)\n",
    "\n",
    "    cursor.executemany(insert_sql, insert_data)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Exported {len(insert_data)} rows to Oracle table filtered_signals\")\n",
    "\n",
    "    # Show distribution\n",
    "    print(f\"\\nSignal type distribution in exported data:\")\n",
    "    print(df_filtered['SIGNAL_TYPE'].value_counts().to_string())\n",
    "    print(f\"\\nSignal direction distribution:\")\n",
    "    print(df_filtered['SIGNAL_DIRECTION'].value_counts().to_string())\n",
    "else:\n",
    "    print(\"Database connection failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
