{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c71c795",
   "metadata": {},
   "source": [
    "# Preprocessing — přehled\n",
    "\n",
    "1. Setup — imports & environment\n",
    "2. Database — načtení `historical_posts` a `historical_comments`\n",
    "3. Load tickers — načtení a normalizace seznamu tickerů (NASDAQ + NYSE)\n",
    "4. Data harmonization <br>\n",
    "   4.1 Sjednocení schémat do `df_unified`<br>\n",
    "   4.2 Placeholder-only rows analysis — analýza řádků s pouze placeholdery<br>\n",
    "   4.3 Odstranění [removed]/[deleted] placeholderů<br>\n",
    "   4.4 Spojení `title` + `body` pro posty do `text`<br>\n",
    "5. EDA — overview, missingness, text length, temporal analysis <br>\n",
    "   5.1 Data types & schema overview — kontrola datových typů<br>\n",
    "   5.2 Column value distributions — unikátní hodnoty, konstantní sloupce<br>\n",
    "   5.3 Overview — counts & missingness<br>\n",
    "   5.4 Text characteristics — word count histograms<br>\n",
    "   5.5 Temporal analysis — day/hour distribution<br>\n",
    "   5.6 Engagement metrics — score & upvote ratio<br>\n",
    "   5.7 Integrity and duplicates — ID uniqueness, authors<br>\n",
    "6. Data Cleaning — odstranění invalidních/prázdných záznamů, deduplikace\n",
    "7. Feature engineering — text_length, word_count, temporal a engagement features, weighted_score\n",
    "8. Ticker detection <br>\n",
    "   8.1 Detekce `mentioned_tickers`, `n_tickers`, `ticker_exchanges`<br>\n",
    "   8.2 Ticker inheritance — inherit parent post tickers to comments + přepočet exchanges<br>\n",
    "   8.3 Inheritance success check — analýza úspěšnosti dědění<br>\n",
    "   8.4 Data Type Conversion — ensure all types persist through pipeline<br>\n",
    "9. Text normalization — lowercase, odstranění URLs/interpunkce, stopword removal (tickers již v mentioned_tickers)\n",
    "10. Export — konverze mentioned_tickers na CSV-friendly string, export `sentiment_ready_data.csv`\n",
    "11. Process Map Visualization — Graphviz vizualizace celého pipeline\n",
    "\n",
    "**Výstup:** `sentiment_ready_data.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f2632",
   "metadata": {},
   "source": [
    "- **Zde dokumentace k Reddit API, kde najdete popis sloupců: https://praw.readthedocs.io/en/stable/code_overview/models/submission.html?utm_source=chatgpt.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc3561",
   "metadata": {},
   "source": [
    "- **Silně Doporučuju stahnout tady ve VScodu extension Data Wrangler od Microsoftu. Je to dobry na divani se na dataframy a jsou tam i nejaky data quality metriky a jde ten df otevrit normalne jako dalsi okno tady ve vscodu aktualizovat ho s tim jak se ten dataframe upravuje v prubehu preprocessingu. Obecne mi to prijde jako mega fajn extension.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358f6b5",
   "metadata": {},
   "source": [
    "- **V levé liště je možná orientace v dokukmentu pomocí OUTLINE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e4feb",
   "metadata": {},
   "source": [
    "- **Většina použitých funkcí je definována v utils.py a importována sem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70ba40",
   "metadata": {},
   "source": [
    "- Za gramatický zločiny jak v cz a en určitě nezodpovídám xd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb93896",
   "metadata": {},
   "source": [
    "**ENJOY THE RUN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb957f",
   "metadata": {},
   "source": [
    "## 1 Setup — Imports & environment\n",
    "\n",
    "Načteme potřebné knihovny a ověříme dostupnost spaCy/NLTK a DB driveru. To nám řekne, které nástroje můžeme použít dál pro čištění a tokenizaci textu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1346aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: imports loaded — available: none\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup: Imports and Configuration\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Set, Dict, Any\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Environment and database imports\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    DOTENV_AVAILABLE = True\n",
    "except ImportError:\n",
    "    DOTENV_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import oracledb\n",
    "    ORACLE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ORACLE_AVAILABLE = False\n",
    "    print(\"Oracle DB not available. Install with: pip install oracledb\")\n",
    "\n",
    "# Checking for NLP libraries (if you lack any - install with pip install)\n",
    "available_libs = []\n",
    "try:\n",
    "    import nltk\n",
    "    NLTK_AVAILABLE = True\n",
    "    available_libs.append(\"NLTK\")\n",
    "\n",
    "    # Check if NLTK stopwords are downloaded\n",
    "    try:\n",
    "        nltk.data.find('corpora/stopwords')\n",
    "        print(\"NLTK stopwords data found\")\n",
    "    except LookupError:\n",
    "        print(\"NLTK stopwords not found. Attempting to download...\")\n",
    "        try:\n",
    "            nltk.download('stopwords', quiet=True)\n",
    "            print(\"NLTK stopwords downloaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download NLTK stopwords: {e}\")\n",
    "            print(\"   Will use fallback stopword list\")\n",
    "except ImportError:\n",
    "    NLTK_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    SPACY_AVAILABLE = True\n",
    "    available_libs.append(\"spaCy\")\n",
    "\n",
    "    # Check if spaCy model is available\n",
    "    try:\n",
    "        spacy.load(\"en_core_web_sm\")\n",
    "        print(\"spaCy 'en_core_web_sm' model found\")\n",
    "    except OSError:\n",
    "        print(\"spaCy model 'en_core_web_sm' not found\")\n",
    "        print(\"   Install with: python -m spacy download en_core_web_sm\")\n",
    "        print(\"   Will fall back to NLTK if available\")\n",
    "except ImportError:\n",
    "    SPACY_AVAILABLE = False\n",
    "\n",
    "# Import functions from utils\n",
    "from utils import (\n",
    "    get_oracle_connection,\n",
    "    get_all_us_tickers,\n",
    "    detect_tickers_in_text,\n",
    "    apply_ticker_detection,\n",
    "    harmonize_schema,\n",
    "    drop_invalid_texts,\n",
    "    deduplicate_and_normalize_types,\n",
    "    add_temporal_features,\n",
    "    add_engagement_features,\n",
    "    apply_text_normalization,\n",
    "    remove_financial_stopwords,\n",
    "    remove_stopwords_spacy\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration constants for minimal text lenght of texts to be considered valid and retry delay for operations\n",
    "MIN_TEXT_LENGTH = 10\n",
    "RETRY_DELAY = 10\n",
    "\n",
    "print(f\"Step 1: imports loaded — available: {', '.join(available_libs) if available_libs else 'none'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70ac2c",
   "metadata": {},
   "source": [
    "## 2 Database — Extract posts & comments\n",
    "\n",
    "Připojíme se k databázi (nebo načteme z cache) a stáhneme posty a komentáře. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10b68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: importing Reddit data from Oracle database\n",
      "Oracle credentials found, so far so good...\n",
      "Oracle connection successful!\n",
      "Database connection successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/xsh6xzj10l121lg2lr_6rpkm0000gn/T/ipykernel_16771/150199243.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_posts = pd.read_sql_query(query_posts, conn)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Query to import posts (number of them is set to 1000 for testing, but can be set in the variable)\u001b[39;00m\n\u001b[32m     24\u001b[39m     query_posts = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[33m        SELECT\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m            author, title, created_utc, id, is_original_content,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33m        -- WHERE ROWNUM <= 1000\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     df_posts = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_posts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Query to import comments (number of them is set to 1000 for testing, but can be set in the variable)\u001b[39;00m\n\u001b[32m     35\u001b[39m     query_comments = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[33m        SELECT\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[33m            author, created_utc, id, parent_post_id, score,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m \u001b[33m        -- WHERE ROWNUM <= 1000\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Škola/5. semestr/TA2/stock-sentiment-analysis/.venv/lib/python3.13/site-packages/pandas/io/sql.py:528\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Škola/5. semestr/TA2/stock-sentiment-analysis/.venv/lib/python3.13/site-packages/pandas/io/sql.py:2743\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2732\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._query_iterator(\n\u001b[32m   2733\u001b[39m         cursor,\n\u001b[32m   2734\u001b[39m         chunksize,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2740\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m   2741\u001b[39m     )\n\u001b[32m   2742\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2743\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetchall_as_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2744\u001b[39m     cursor.close()\n\u001b[32m   2746\u001b[39m     frame = _wrap_result(\n\u001b[32m   2747\u001b[39m         data,\n\u001b[32m   2748\u001b[39m         columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2753\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m   2754\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Škola/5. semestr/TA2/stock-sentiment-analysis/.venv/lib/python3.13/site-packages/pandas/io/sql.py:2758\u001b[39m, in \u001b[36mSQLiteDatabase._fetchall_as_list\u001b[39m\u001b[34m(self, cur)\u001b[39m\n\u001b[32m   2757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fetchall_as_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, cur):\n\u001b[32m-> \u001b[39m\u001b[32m2758\u001b[39m     result = \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetchall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2759\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m   2760\u001b[39m         result = \u001b[38;5;28mlist\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Škola/5. semestr/TA2/stock-sentiment-analysis/.venv/lib/python3.13/site-packages/oracledb/cursor.py:793\u001b[39m, in \u001b[36mCursor.fetchall\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    791\u001b[39m fetch_next_row = \u001b[38;5;28mself\u001b[39m._impl.fetch_next_row\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m     row = \u001b[43mfetch_next_row\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    795\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/oracledb/impl/base/cursor.pyx:604\u001b[39m, in \u001b[36moracledb.base_impl.BaseCursorImpl.fetch_next_row\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/oracledb/impl/thin/cursor.pyx:266\u001b[39m, in \u001b[36moracledb.thin_impl.ThinCursorImpl._fetch_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/oracledb/impl/thin/protocol.pyx:482\u001b[39m, in \u001b[36moracledb.thin_impl.Protocol._process_single_message\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/oracledb/impl/thin/protocol.pyx:483\u001b[39m, in \u001b[36moracledb.thin_impl.Protocol._process_single_message\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/oracledb/impl/thin/protocol.pyx:426\u001b[39m, in \u001b[36moracledb.thin_impl.Protocol._process_message\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/oracledb/impl/thin/protocol.pyx:499\u001b[39m, in \u001b[36moracledb.thin_impl.Protocol._receive_packet\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/oracledb/impl/thin/packet.pyx:759\u001b[39m, in \u001b[36moracledb.thin_impl.ReadBuffer.wait_for_packets_sync\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/oracledb/impl/thin/transport.pyx:345\u001b[39m, in \u001b[36moracledb.thin_impl.Transport.read_packet\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 2. Database Connection: Loading Reddit Data from Oracle\n",
    "\n",
    "print(\"Step 2: importing Reddit data from Oracle database\")\n",
    "\n",
    "# Check if Oracle DB is available and credentials are set in environment variables\n",
    "oracle_credentials_available = (\n",
    "    ORACLE_AVAILABLE and\n",
    "    os.getenv('db-username') and\n",
    "    os.getenv('db-password') and\n",
    "    os.getenv('db-dsn')\n",
    ")\n",
    "\n",
    "if oracle_credentials_available:\n",
    "    print(\"Oracle credentials found, so far so good...\")\n",
    "\n",
    "    conn = get_oracle_connection()\n",
    "\n",
    "    if conn:\n",
    "        print(\"Database connection successful\")\n",
    "\n",
    "        # Importing data from database\n",
    "        try:\n",
    "            # Query to import posts (number of them is set to 1000 for testing, but can be set in the variable)\n",
    "            query_posts = \"\"\"\n",
    "                SELECT\n",
    "                    author, title, created_utc, id, is_original_content,\n",
    "                    score, DBMS_LOB.SUBSTR(body, 4000, 1) as body,\n",
    "                    subreddit, upvote_ratio, url\n",
    "                FROM historical_posts\n",
    "                WHERE ROWNUM <= 1000\n",
    "            \"\"\"\n",
    "            df_posts = pd.read_sql_query(query_posts, conn)\n",
    "\n",
    "            # Query to import comments (number of them is set to 1000 for testing, but can be set in the variable)\n",
    "            query_comments = \"\"\"\n",
    "                SELECT\n",
    "                    author, created_utc, id, parent_post_id, score,\n",
    "                    DBMS_LOB.SUBSTR(body, 4000, 1) as body,\n",
    "                    subreddit\n",
    "                FROM historical_comments\n",
    "                WHERE ROWNUM <= 1000\n",
    "            \"\"\"\n",
    "            df_comments = pd.read_sql_query(query_comments, conn)\n",
    "\n",
    "            # Closing connection immediately after data import so that it does not stay open longer than needed\n",
    "            conn.close()\n",
    "\n",
    "            print(f\"\\nPosts imported: {df_posts.shape}\")\n",
    "            print(f\"Comments imported: {df_comments.shape}\")\n",
    "\n",
    "            if len(df_posts) > 0:\n",
    "                print(f\"Posts columns: {list(df_posts.columns)}\")\n",
    "\n",
    "            if len(df_comments) > 0:\n",
    "                print(f\"Comments columns: {list(df_comments.columns)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error importing data from database: {e}\")\n",
    "            if conn:\n",
    "                try:\n",
    "                    conn.close()\n",
    "                except:\n",
    "                    pass\n",
    "            df_posts = pd.DataFrame()\n",
    "            df_comments = pd.DataFrame()\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to connect to database - check logs, kinda cooked you are\")\n",
    "        df_posts = pd.DataFrame()\n",
    "        df_comments = pd.DataFrame()\n",
    "\n",
    "else:\n",
    "    print(\"Oracle database credentials not configured — set them in .env file or environment variables\")\n",
    "    df_posts = pd.DataFrame()\n",
    "    df_comments = pd.DataFrame()\n",
    "\n",
    "print(f\"\\nStep 2 complete: Loaded {len(df_posts)} posts and {len(df_comments)} comments. Letzgoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63cd0401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 AUTHOR                                              TITLE  \\\n",
      "0           BrockForsey  40K in traditional IRA. Should I transfer to m...   \n",
      "1  Legitimate_Author_20  could you a suggestion for splitting my 50,000...   \n",
      "2             fxroy5673  ✅ I Offer clear, concise signals backed by tho...   \n",
      "3  Few-Professional-859                Good time for semiconductor stocks?   \n",
      "4         CyrilPCallist             Begineer looking for investing advice    \n",
      "\n",
      "   CREATED_UTC       ID  IS_ORIGINAL_CONTENT  SCORE  \\\n",
      "0   1721474597  1e7tfbb                    0      3   \n",
      "1   1721475391  1e7tmnc                    0      1   \n",
      "2   1721475575  1e7tobx                    0      1   \n",
      "3   1721477170  1e7u4jj                    0      1   \n",
      "4   1721480593  1e7v5s3                    0      1   \n",
      "\n",
      "                                                BODY  SUBREDDIT  UPVOTE_RATIO  \\\n",
      "0  Potentially relevant details: 36 yo, married, ...  investing          0.57   \n",
      "1                                          [removed]  investing          0.50   \n",
      "2                                          [removed]  investing          1.00   \n",
      "3                                          [removed]  investing          1.00   \n",
      "4                                          [removed]  investing          1.00   \n",
      "\n",
      "                                                 URL  \n",
      "0  https://www.reddit.com/r/investing/comments/1e...  \n",
      "1  https://www.reddit.com/r/investing/comments/1e...  \n",
      "2  https://www.reddit.com/r/investing/comments/1e...  \n",
      "3  https://www.reddit.com/r/investing/comments/1e...  \n",
      "4  https://www.reddit.com/r/investing/comments/1e...  \n"
     ]
    }
   ],
   "source": [
    "print(df_posts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038a1630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   AUTHOR                                              TITLE  \\\n",
      "0             BrockForsey  40K in traditional IRA. Should I transfer to m...   \n",
      "1    Legitimate_Author_20  could you a suggestion for splitting my 50,000...   \n",
      "2               fxroy5673  ✅ I Offer clear, concise signals backed by tho...   \n",
      "3    Few-Professional-859                Good time for semiconductor stocks?   \n",
      "4           CyrilPCallist             Begineer looking for investing advice    \n",
      "..                    ...                                                ...   \n",
      "995            Astrid-427        What's the most underrated stock right now?   \n",
      "996           chinoaleman  Why is $KSS so low despite a good P/E ratio? W...   \n",
      "997            Astrid-427                Do you consider $RICK a good stock?   \n",
      "998           nachihapter  Response to Thread - 'Should we buy Reddit (RD...   \n",
      "999      Efficient-Ad3985         Seeking Help with Stock Pitch Presentation   \n",
      "\n",
      "     CREATED_UTC       ID  IS_ORIGINAL_CONTENT  SCORE  \\\n",
      "0     1721474597  1e7tfbb                    0      3   \n",
      "1     1721475391  1e7tmnc                    0      1   \n",
      "2     1721475575  1e7tobx                    0      1   \n",
      "3     1721477170  1e7u4jj                    0      1   \n",
      "4     1721480593  1e7v5s3                    0      1   \n",
      "..           ...      ...                  ...    ...   \n",
      "995   1728429788  1fzdndo                    0      1   \n",
      "996   1728431619  1fzea19                    0      3   \n",
      "997   1728431894  1fzed84                    0      2   \n",
      "998   1728432717  1fzenet                    0      1   \n",
      "999   1728433899  1fzf1jz                    0      6   \n",
      "\n",
      "                                                  BODY       SUBREDDIT  \\\n",
      "0    Potentially relevant details: 36 yo, married, ...       investing   \n",
      "1                                            [removed]       investing   \n",
      "2                                            [removed]       investing   \n",
      "3                                            [removed]       investing   \n",
      "4                                            [removed]       investing   \n",
      "..                                                 ...             ...   \n",
      "995  I guess this is something that gets asked a lo...  ValueInvesting   \n",
      "996  I've seen that KSS has dropped a lot in the la...  ValueInvesting   \n",
      "997  Hey everyone, I'm curious to know your thought...  ValueInvesting   \n",
      "998  Let's buy it. Let's say I have access to lot o...  ValueInvesting   \n",
      "999  Hello everyone, I hope this message finds you ...  ValueInvesting   \n",
      "\n",
      "     UPVOTE_RATIO                                                URL  \n",
      "0            0.57  https://www.reddit.com/r/investing/comments/1e...  \n",
      "1            0.50  https://www.reddit.com/r/investing/comments/1e...  \n",
      "2            1.00  https://www.reddit.com/r/investing/comments/1e...  \n",
      "3            1.00  https://www.reddit.com/r/investing/comments/1e...  \n",
      "4            1.00  https://www.reddit.com/r/investing/comments/1e...  \n",
      "..            ...                                                ...  \n",
      "995          1.00  https://www.reddit.com/r/ValueInvesting/commen...  \n",
      "996          0.72  https://www.reddit.com/r/ValueInvesting/commen...  \n",
      "997          0.57  https://www.reddit.com/r/ValueInvesting/commen...  \n",
      "998          0.14  https://www.reddit.com/r/ValueInvesting/commen...  \n",
      "999          0.75  https://www.reddit.com/r/ValueInvesting/commen...  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba52502",
   "metadata": {},
   "source": [
    "## 3 Load tickers — Ticker list & exchanges\n",
    "\n",
    "Načteme a normalizujeme seznam tickerů (lokálně nebo ze zdroje) - podívej se na strukturu toho csvcka. Podíváme se na rozložení tickerů dle burzy (vychází pořád z toho csvcka)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bd8a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8003 cached tickers\n",
      "  Exchanges: {'NASDAQ': 5118, 'NYSE': 2885}\n",
      "\n",
      "Step 3 complete: Loaded 8003 ticker symbols. Letzgoo\n"
     ]
    }
   ],
   "source": [
    "# 3. Ticker Data Loading: Fetch NASDAQ/NYSE Symbols\n",
    "us_tickers_path = \"us_tickers.csv\"\n",
    "\n",
    "if os.path.exists(us_tickers_path):\n",
    "    try:\n",
    "        tickers_df = pd.read_csv(us_tickers_path, dtype=str)\n",
    "        tickers_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in tickers_df.columns]\n",
    "        if 'ticker' in tickers_df.columns:\n",
    "            tickers_df['ticker'] = tickers_df['ticker'].astype(str).str.upper().str.strip()\n",
    "        print(f\"Loaded {len(tickers_df)} cached tickers\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading cached data: {e}\")\n",
    "        tickers_df = None\n",
    "else:\n",
    "    tickers_df = None\n",
    "\n",
    "# If no cached data or fresh data\n",
    "if tickers_df is None or len(tickers_df) == 0:\n",
    "    try:\n",
    "        tickers_df = get_all_us_tickers()\n",
    "        if len(tickers_df) > 0:\n",
    "            tickers_df.to_csv(us_tickers_path, index=False)\n",
    "            print(f\"Fetched and cached {len(tickers_df)} US tickers\")\n",
    "        else:\n",
    "            print(\"No ticker data retrieved - this should not happen xd\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching ticker data: {e}\")\n",
    "        tickers_df = pd.DataFrame()\n",
    "\n",
    "if len(tickers_df) > 0:\n",
    "    print(f\"  Exchanges: {tickers_df['exchange'].value_counts().to_dict()}\")\n",
    "\n",
    "else:\n",
    "    print(\"No ticker data available - ur cooked bro\")\n",
    "\n",
    "print(f\"\\nStep 3 complete: Loaded {len(tickers_df)} ticker symbols. Letzgoo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288a0b5",
   "metadata": {},
   "source": [
    "## 4 Data harmonization — unify posts & comments\n",
    "\n",
    "Sjednotíme posts a comments do jednoho `df_unified` s konzistentními sloupci (id, text, type, title, parent_post_id...). Myslel jsem, že tohle bude dočasný řešení (takový temporary zjednoduseni) a divani se na posty a komenty uplne stejne, ale nakonec jde skrze parent_post_id hezky mapovat napříč daty takže bych to dělal takhle (bude dávat větší smysl to co píšu v dalších krocích i guess)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b336fa",
   "metadata": {},
   "source": [
    "### 4.1 Unifying posts & comments\n",
    "\n",
    "Sloučíme **df_posts** a **df_comments**, přemapujeme názvy a vytvoříme jednotný sloupec `text`, ktery bude ten nejdulezitejsi sloupec na pozdejsi analyzu basically. Tady je ořekávané to, že u sloupců, které posty mají jen posty, vzniknou v tom samém sloupci pro komentáře NAs. A naopak. To je v pořádku a řešíme to dále."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21117e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ozetek/Documents/Škola/5. semestr/TA2/stock-sentiment-analysis/utils.py:298: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  unified = pd.concat([posts, comments], ignore_index=True, sort=False)\n",
      "INFO:utils:Harmonized schema. Unified dataframe shape: (2000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified dataframe shape: (2000, 12)\n",
      "Unified columns: ['author', 'title', 'created_utc', 'id', 'is_original_content', 'score', 'text', 'subreddit', 'upvote_ratio', 'url', 'parent_post_id', 'type']\n",
      "\n",
      "Data distribution:\n",
      "  post: 1000 rows\n",
      "  comment: 1000 rows\n",
      "\n",
      "Step 4.1 complete: Unified 2000 rows. Letzgoo\n"
     ]
    }
   ],
   "source": [
    "# 4. Data Harmonization: Merge Posts and Comments\n",
    "\n",
    "if len(df_posts) > 0 or len(df_comments) > 0:\n",
    "    # combining data\n",
    "    df_unified = harmonize_schema(df_posts, df_comments)\n",
    "    print(f\"Unified dataframe shape: {df_unified.shape}\")\n",
    "    print(f\"Unified columns: {list(df_unified.columns)}\")\n",
    "\n",
    "    # data type distribution\n",
    "    type_counts = df_unified['type'].value_counts()\n",
    "    print(f\"\\nData distribution:\")\n",
    "    for dtype, count in type_counts.items():\n",
    "        print(f\"  {dtype}: {count} rows\")\n",
    "\n",
    "else:\n",
    "    print(\"No data to harmonize\")\n",
    "    df_unified = pd.DataFrame()\n",
    "\n",
    "print(f\"\\nStep 4.1 complete: Unified {len(df_unified)} rows. Letzgoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd96a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 author                                              title  \\\n",
      "0           BrockForsey  40K in traditional IRA. Should I transfer to m...   \n",
      "1  Legitimate_Author_20  could you a suggestion for splitting my 50,000...   \n",
      "2             fxroy5673  ✅ I Offer clear, concise signals backed by tho...   \n",
      "3  Few-Professional-859                Good time for semiconductor stocks?   \n",
      "4         CyrilPCallist             Begineer looking for investing advice    \n",
      "\n",
      "   created_utc       id is_original_content  score  \\\n",
      "0   1721474597  1e7tfbb                   0      3   \n",
      "1   1721475391  1e7tmnc                   0      1   \n",
      "2   1721475575  1e7tobx                   0      1   \n",
      "3   1721477170  1e7u4jj                   0      1   \n",
      "4   1721480593  1e7v5s3                   0      1   \n",
      "\n",
      "                                                text  subreddit  upvote_ratio  \\\n",
      "0  Potentially relevant details: 36 yo, married, ...  investing          0.57   \n",
      "1                                          [removed]  investing          0.50   \n",
      "2                                          [removed]  investing          1.00   \n",
      "3                                          [removed]  investing          1.00   \n",
      "4                                          [removed]  investing          1.00   \n",
      "\n",
      "                                                 url parent_post_id  type  \n",
      "0  https://www.reddit.com/r/investing/comments/1e...           None  post  \n",
      "1  https://www.reddit.com/r/investing/comments/1e...           None  post  \n",
      "2  https://www.reddit.com/r/investing/comments/1e...           None  post  \n",
      "3  https://www.reddit.com/r/investing/comments/1e...           None  post  \n",
      "4  https://www.reddit.com/r/investing/comments/1e...           None  post  \n"
     ]
    }
   ],
   "source": [
    "print(df_unified.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09e66d",
   "metadata": {},
   "source": [
    "### 4.2 Placeholder-only rows analysis\n",
    "\n",
    "Některé řádky mají **pouze** placeholdery ([removed]/[deleted]) - tohle bylo zjisteno na zaklade inspekce dataframu, ale stejně by to bylo zjištěno později. Tyhle sloupce nemají žádný skutečný obsah → budou smazány v dalším kroku. Tady se podíváme kolik takových řádků máme, a jak jsou rozloženy podle typu (posty vs komenty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0439c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Placeholder-Only Rows by Type:\n",
      "  COMMENT: 34 rows will be deleted\n",
      "    text: [removed]=33, [deleted]=1, empty/NA=0\n"
     ]
    }
   ],
   "source": [
    "if len(df_unified) == 0:\n",
    "    print(\"No data\")\n",
    "else:\n",
    "    def is_placeholder(s):\n",
    "        if pd.isna(s):\n",
    "            return True\n",
    "        s = str(s).strip().lower()\n",
    "        return s == '' or s in {'[deleted]', '[removed]', 'nan'}\n",
    "\n",
    "    text_placeholder = df_unified['text'].apply(is_placeholder)\n",
    "    title_placeholder = df_unified.get('title', pd.Series(False, index=df_unified.index)).apply(is_placeholder)\n",
    "\n",
    "    to_drop_mask = (\n",
    "        ((df_unified['type'] == 'post') & title_placeholder & text_placeholder) |\n",
    "        ((df_unified['type'] == 'comment') & text_placeholder)\n",
    "    )\n",
    "\n",
    "    if to_drop_mask.any():\n",
    "        print(\"\\nPlaceholder-Only Rows by Type:\")\n",
    "\n",
    "        for t, grp in df_unified[to_drop_mask].groupby('type'):\n",
    "            print(f\"  {t.upper()}: {len(grp):,} rows will be deleted\")\n",
    "\n",
    "            if t == 'post':\n",
    "                for col in ['title', 'text']:\n",
    "                    removed = (grp[col].str.strip().str.lower() == '[removed]').sum()\n",
    "                    deleted = (grp[col].str.strip().str.lower() == '[deleted]').sum()\n",
    "                    print(f\"    {col}: [removed]={removed:,}, [deleted]={deleted:,}\")\n",
    "            else:\n",
    "                txt = grp['text'].astype(str).str.strip().str.lower()\n",
    "                removed = (txt == '[removed]').sum()\n",
    "                deleted = (txt == '[deleted]').sum()\n",
    "                empty = (txt == '').sum()\n",
    "                print(f\"    text: [removed]={removed:,}, [deleted]={deleted:,}, empty/NA={empty:,}\")\n",
    "    else:\n",
    "        print(\"No placeholder-only rows found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b9e32",
   "metadata": {},
   "source": [
    "**Oukej, vypadá to, že vždy jsou plný placeholderů jen komenty (většinou [removed])** S lehkým srdcem toto 1% dat mažem v příštím kroku xd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534dc37f",
   "metadata": {},
   "source": [
    "### 4.3 deleting [removed]/[deleted] placeholders (**NOT REMOVING MISSING VALUES - THESE ARE HANDLED LATER**)\n",
    "\n",
    "Místo samotných NAs, je v nadpisech Tohle je udelany, abychom pri pozdejsim feature engineeringu nedostali neco jako: \"Emotional investing research. [removed]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ebd542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We removed 34 placeholder-only rows (kept posts with title if present).\n"
     ]
    }
   ],
   "source": [
    "# turning placeholders into empty string\n",
    "if 'title' in df_unified.columns:\n",
    "    df_unified['title'] = df_unified['title'].apply(lambda x: '' if is_placeholder(x) else str(x).strip())\n",
    "if 'text' in df_unified.columns:\n",
    "    df_unified['text'] = df_unified['text'].apply(lambda x: '' if is_placeholder(x) else str(x).strip())\n",
    "\n",
    "# Droping posts where both title and text are empty after cleaning\n",
    "before = len(df_unified)\n",
    "mask_empty_post = (df_unified['type'] == 'post') & (df_unified.get('title', '').astype(str).str.strip() == '') & (df_unified.get('text', '').astype(str).str.strip() == '')\n",
    "mask_empty_comment = (df_unified['type'] == 'comment') & (df_unified.get('text', '').astype(str).str.strip() == '')\n",
    "\n",
    "# For comments we will drop those with empty body. For posts we will drop only if both title+text empty\n",
    "to_drop = mask_empty_post | mask_empty_comment\n",
    "df_unified = df_unified[~to_drop].reset_index(drop=True)\n",
    "after = len(df_unified)\n",
    "print(f\"We removed {before - after} placeholder-only rows (kept posts with title if present).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6dbfb",
   "metadata": {},
   "source": [
    "### 4.4 Merging title + body for posts into **text** column\n",
    "\n",
    "U postů spojíme `title` s tělem, protože titul často obsahuje klíčovou informaci nebo ticker. Title a to tělo spolu přímo souvisí a je to vlastně jedna entita (tedy post). Reálně není důvod proč to neudělat a navíc můžeme poté smazat sloupec title, který byl stejně z půlky NAs (komentare nemaji title), což prakticky nevadilo ale vis co o sloupec min lol. Zvýší to později šanci, že detekce tickerů a sentimentu zachytí o čem post reálně je."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b013ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 'title' column (merged into 'text')\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# 4.4 Enhanced Text: Merge Title + Body for Posts\n",
    "\n",
    "if len(df_unified) > 0:\n",
    "\n",
    "    # For posts: concatenate title + body\n",
    "    # For comments: keep body only (no title)\n",
    "    def create_enhanced_text(row):\n",
    "        if row['type'] == 'post':\n",
    "            title = str(row.get('title', '')).strip()\n",
    "            body = str(row.get('text', '')).strip()\n",
    "            # Combine title and body with separator\n",
    "            if title and title != 'nan' and body and body != 'nan':\n",
    "                return f\"{title}. {body}\"\n",
    "            elif title and title != 'nan':\n",
    "                return title\n",
    "            elif body and body != 'nan':\n",
    "                return body\n",
    "            else:\n",
    "                return ''\n",
    "        else:\n",
    "            # Comments: use text only\n",
    "            return str(row.get('text', '')).strip()\n",
    "\n",
    "    df_unified['enhanced_text'] = df_unified.apply(create_enhanced_text, axis=1)\n",
    "\n",
    "    # Replace 'text' column with enhanced version\n",
    "    df_unified['text'] = df_unified['enhanced_text']\n",
    "    df_unified.drop(columns=['enhanced_text'], inplace=True)\n",
    "\n",
    "    # We can safely rop title column since it's now merged into text (and later ticker detection is done on the \"text\" column)\n",
    "    if 'title' in df_unified.columns:\n",
    "        df_unified.drop(columns=['title'], inplace=True)\n",
    "        print(\"Dropped 'title' column (merged into 'text')\")\n",
    "\n",
    "    print(f\"Done\")\n",
    "\n",
    "else:\n",
    "    print(\"No data to enhance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8739232b",
   "metadata": {},
   "source": [
    "## 5 Exploratory Data Analysis (EDA)\n",
    "\n",
    "Projdeme kvalitu dat a základní statistiky, abychom věděli jak data dál (pokud je to potřeba) upravit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af08cff",
   "metadata": {},
   "source": [
    "### 5.1 Data types chekc/conversion & schema overview\n",
    "\n",
    "Zkontrolujeme datové typy všech sloupců a případně je upravíme. To nám pomůže identifikovat potenciální problémy v datech a zajistit správné zpracování v dalších krocích."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bfcbf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1966, 11)\n",
      "  author               : object         \n",
      "  created_utc          : int64          \n",
      "  id                   : object         \n",
      "  is_original_content  : object         \n",
      "  score                : int64          \n",
      "  text                 : object         \n",
      "  subreddit            : object         \n",
      "  upvote_ratio         : float64        \n",
      "  url                  : object         \n",
      "  parent_post_id       : object         \n",
      "  type                 : object         \n"
     ]
    }
   ],
   "source": [
    "# 5.1 Data types check\n",
    "\n",
    "if len(df_unified) > 0:\n",
    "    print(f\"Dataset shape: {df_unified.shape}\")\n",
    "\n",
    "    for col in df_unified.columns:\n",
    "        dtype = df_unified[col].dtype\n",
    "        print(f\"  {col:20} : {str(dtype):15}\")\n",
    "\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfdc95",
   "metadata": {},
   "source": [
    "**Everything seems fine. Data type conversion is now performed after Step 8.2 (ticker inheritance) to ensure types persist through the entire pipeline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e02bd",
   "metadata": {},
   "source": [
    "### 5.2 Column value distributions\n",
    "\n",
    "Prozkoumáme rozložení hodnot ve sloupcích - počty unikátních hodnot, konstantní sloupce a základní distribuce kategorických proměnných."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b09d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Value Counts:\n",
      "  author               : 1,546 unique values (78.6% of total)\n",
      "  created_utc          : 1,956 unique values (99.5% of total)\n",
      "  id                   : 1,966 unique values (100.0% of total)\n",
      "  is_original_content  : 1 unique values (0.1% of total)\n",
      "  score                : 100 unique values (5.1% of total)\n",
      "  text                 : 1,915 unique values (97.4% of total)\n",
      "  subreddit            : 3 unique values (0.2% of total)\n",
      "  upvote_ratio         : 85 unique values (4.3% of total)\n",
      "  url                  : 990 unique values (50.4% of total)\n",
      "  parent_post_id       : 216 unique values (11.0% of total)\n",
      "  type                 : 2 unique values (0.1% of total)\n",
      "\n",
      "Step 5.2 completed\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Column Value Distributions\n",
    "\n",
    "if len(df_unified) > 0:\n",
    "    print(\"\\nUnique Value Counts:\")\n",
    "\n",
    "    for col in df_unified.columns:\n",
    "        n_unique = df_unified[col].nunique()\n",
    "        n_total = len(df_unified)\n",
    "        pct_unique = (n_unique / n_total) * 100\n",
    "\n",
    "        print(f\"  {col:20} : {n_unique:,} unique values ({pct_unique:.1f}% of total)\")\n",
    "\n",
    "    print(f\"\\nStep 5.2 completed\")\n",
    "\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664b963e",
   "metadata": {},
   "source": [
    "**[is_original_content] má jen hodnotu 0, takže ho později dropnem. Nic jinýho podlě mě neznačí nějaký problémy kvůli kterým by stálo za to tohle nějak dále analyzovat či data upravovat.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcaee71",
   "metadata": {},
   "source": [
    "### 5.3 Overview — counts & missingness \n",
    "\n",
    "Spočítáme počty, podíly chybějících hodnot a zjistíme, kolik záznamů je smazaných nebo prázdných (NAs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5316784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAs by Column:\n",
      "  is_original_content: 966 (49.1%)\n",
      "  upvote_ratio: 966 (49.1%)\n",
      "  url: 974 (49.5%)\n",
      "  parent_post_id: 1,000 (50.9%)\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Data Quality & Completeness\n",
    "if len(df_unified) > 0:\n",
    "\n",
    "    print(\"\\nNAs by Column:\")\n",
    "    for col in df_unified.columns:\n",
    "        missing_count = df_unified[col].isna().sum()\n",
    "        if missing_count > 0:\n",
    "            missing_pct = (missing_count / len(df_unified)) * 100\n",
    "            print(f\"  {col}: {missing_count:,} ({missing_pct:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"No data available for quality analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249908ea",
   "metadata": {},
   "source": [
    "Všechno je v pořádku — chybějící hodnoty v  [is_original_content], [upvote_ratio], [url], [parent_post_id] jsou strukturální (posty vs. komentáře mají původně různé sloupce). V data cleaning dropneme is_original_content, url. **Naopak [parent_post_id] určitě nedropujeme.** <br>\n",
    "\n",
    "Very short texts (≤5 chars): 104 — ty budou odstraněny v kroku 6 (drop_invalid_texts). <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c830b",
   "metadata": {},
   "source": [
    "### 5.4 Text characteristics\n",
    "\n",
    "Podíváme se na délky textů, počty slov a percentily, abychom kdyžtak vyfiltrovali moc krátký/dlouhý (druhá možnost spíše ne, není proč). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d022867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Count Statistics (Overall):\n",
      "  Mean: 55.9 words\n",
      "  Median: 21.0 words\n",
      "  Min: 1 words\n",
      "  Max: 739 words\n",
      "matplotlib not available - install with: pip install matplotlib\n",
      "\n",
      "Quality Issues:\n",
      "  Texts ≤10 chars: 43 (2.2%)\n"
     ]
    }
   ],
   "source": [
    "# 5.4 Text Characteristics\n",
    "\n",
    "if len(df_unified) > 0 and 'text' in df_unified.columns:\n",
    "\n",
    "    # Calculating text statistics\n",
    "    valid_texts = df_unified[df_unified['text'].notna() & (df_unified['text'] != '')]\n",
    "\n",
    "    if len(valid_texts) > 0:\n",
    "        text_lengths = valid_texts['text'].astype(str).str.len()\n",
    "\n",
    "        word_counts = valid_texts['text'].astype(str).str.split().str.len()\n",
    "\n",
    "        print(f\"\\nWord Count Statistics (Overall):\")\n",
    "        print(f\"  Mean: {word_counts.mean():.1f} words\")\n",
    "        print(f\"  Median: {word_counts.median():.1f} words\")\n",
    "        print(f\"  Min: {word_counts.min()} words\")\n",
    "        print(f\"  Max: {word_counts.max()} words\")\n",
    "\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            if 'type' in valid_texts.columns:\n",
    "                posts = valid_texts[valid_texts['type'] == 'post']\n",
    "                comments = valid_texts[valid_texts['type'] == 'comment']\n",
    "\n",
    "                if len(posts) > 0 and len(comments) > 0:\n",
    "                    post_word_counts = posts['text'].astype(str).str.split().str.len()\n",
    "                    comment_word_counts = comments['text'].astype(str).str.split().str.len()\n",
    "\n",
    "                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "                    # Posts\n",
    "                    ax1.hist(post_word_counts, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "                    ax1.axvline(post_word_counts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {post_word_counts.mean():.1f}')\n",
    "                    ax1.axvline(post_word_counts.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {post_word_counts.median():.1f}')\n",
    "                    ax1.set_xlabel('Number of Words')\n",
    "                    ax1.set_ylabel('Frequency')\n",
    "                    ax1.set_title(f'Posts - Word Count Distribution (n={len(posts):,})')\n",
    "                    ax1.legend()\n",
    "                    ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "                    # Comments\n",
    "                    ax2.hist(comment_word_counts, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "                    ax2.axvline(comment_word_counts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {comment_word_counts.mean():.1f}')\n",
    "                    ax2.axvline(comment_word_counts.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {comment_word_counts.median():.1f}')\n",
    "                    ax2.set_xlabel('Number of Words')\n",
    "                    ax2.set_ylabel('Frequency')\n",
    "                    ax2.set_title(f'Comments - Word Count Distribution (n={len(comments):,})')\n",
    "                    ax2.legend()\n",
    "                    ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(\"  Not enough data for separate histograms\")\n",
    "\n",
    "        except ImportError:\n",
    "            print(\"matplotlib not available - install with: pip install matplotlib\")\n",
    "\n",
    "        # Short texts identification\n",
    "        very_short = (text_lengths <= MIN_TEXT_LENGTH).sum()\n",
    "        print(f\"\\nQuality Issues:\")\n",
    "        print(f\"  Texts ≤{MIN_TEXT_LENGTH} chars: {very_short:,} ({very_short/len(valid_texts)*100:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"No text data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e4445",
   "metadata": {},
   "source": [
    "**Reálně tu není moc řešit. Tak asi nějak co bychom očekávali. Ten rozdíl není nijak margantní, ale i kdyby byl tak pro účely našeho tasku něco jako outlier v počtu slov neexistuje xd.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960d814",
   "metadata": {},
   "source": [
    "### 5.5 Temporal analysis\n",
    "\n",
    "Zkontrolujeme časové rozložení příspěvků (denní/hodinové špičky a rozsah dat). To zajímá jen mě osobně, nejspíš to nebude důležitý, but u never know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddec0014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Date Range:\n",
      "  Earliest: 2024-02-03 13:20:21\n",
      "  Latest: 2024-11-13 23:17:45\n",
      "  Span: 284 days\n",
      "  Mean posts per day: 42.7\n",
      "\n",
      "Temporal Distribution Charts:\n",
      "  matplotlib not available - install with: pip install matplotlib\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.5 Temporal Analysis\n",
    "\n",
    "if len(df_unified) > 0 and 'created_utc' in df_unified.columns:\n",
    "\n",
    "    # Converting to datetime\n",
    "    valid_dates = df_unified[df_unified['created_utc'].notna()].copy()\n",
    "\n",
    "    if len(valid_dates) > 0:\n",
    "        valid_dates['datetime'] = pd.to_datetime(valid_dates['created_utc'], unit='s')\n",
    "\n",
    "        # Date range\n",
    "        print(f\"\\nDate Range:\")\n",
    "        print(f\"  Earliest: {valid_dates['datetime'].min()}\")\n",
    "        print(f\"  Latest: {valid_dates['datetime'].max()}\")\n",
    "        print(f\"  Span: {(valid_dates['datetime'].max() - valid_dates['datetime'].min()).days} days\")\n",
    "\n",
    "        valid_dates['date'] = valid_dates['datetime'].dt.date\n",
    "        valid_dates['hour'] = valid_dates['datetime'].dt.hour\n",
    "        valid_dates['day_of_week'] = valid_dates['datetime'].dt.day_name()\n",
    "        valid_dates['month'] = valid_dates['datetime'].dt.month\n",
    "\n",
    "        # Posts per day\n",
    "        daily_counts = valid_dates.groupby('date').size()\n",
    "        print(f\"  Mean posts per day: {daily_counts.mean():.1f}\")\n",
    "\n",
    "        # temporal patterns\n",
    "        print(f\"\\nTemporal Distribution Charts:\")\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "            day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "            day_counts = valid_dates['day_of_week'].value_counts()\n",
    "            day_counts_ordered = [int(day_counts.get(d, 0)) for d in day_order]\n",
    "            ax1.bar(range(7), day_counts_ordered, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "            ax1.set_xlabel('Day of Week')\n",
    "            ax1.set_ylabel('Number of Posts')\n",
    "            ax1.set_title('Activity by Day of Week')\n",
    "            ax1.set_xticks(range(7))\n",
    "            ax1.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "            ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "            hour_counts = valid_dates['hour'].value_counts()\n",
    "            hours = list(range(24))\n",
    "            counts = [hour_counts.get(h, 0) for h in hours]\n",
    "            ax2.bar(hours, counts, color='coral', alpha=0.7, edgecolor='black')\n",
    "            ax2.set_xlabel('Hour of Day')\n",
    "            ax2.set_ylabel('Number of Posts')\n",
    "            ax2.set_title('Hourly Activity Distribution')\n",
    "            ax2.set_xticks(range(0, 24, 2))\n",
    "            ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        except ImportError:\n",
    "            print(\"  matplotlib not available - install with: pip install matplotlib\")\n",
    "\n",
    "    print()\n",
    "else:\n",
    "    print(\"Warning: No temporal data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e94f5",
   "metadata": {},
   "source": [
    "**Oukej, peak je úterý/středa a většinou odpolední/večerní hodiny.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e2f8b",
   "metadata": {},
   "source": [
    "### 5.6 Upvote ratio analysis\n",
    "\n",
    "Analyzujeme upvote_ratio - poměr kladných hodnocení (upvotes / (upvotes + downvotes)). Tato metrika je dostupná pouze pro posty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333fbfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean: 0.825\n",
      "  Median: 1.000\n",
      "  Min: 0.080\n",
      "  Max: 1.000\n",
      "\n",
      "Upvote Ratio Histogram:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.6 Upvote Ratio Analysis\n",
    "\n",
    "if len(df_unified) > 0:\n",
    "    if 'upvote_ratio' in df_unified.columns:\n",
    "        posts = df_unified[df_unified['type'] == 'post']\n",
    "\n",
    "        if len(posts) > 0 and 'upvote_ratio' in posts.columns:\n",
    "            upvote_ratios = posts['upvote_ratio'].dropna()\n",
    "\n",
    "            if len(upvote_ratios) > 0:\n",
    "                print(f\"  Mean: {upvote_ratios.mean():.3f}\")\n",
    "                print(f\"  Median: {upvote_ratios.median():.3f}\")\n",
    "                print(f\"  Min: {upvote_ratios.min():.3f}\")\n",
    "                print(f\"  Max: {upvote_ratios.max():.3f}\")\n",
    "\n",
    "\n",
    "            print(f\"\\nUpvote Ratio Histogram:\")\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "            # Histogram\n",
    "            ax.hist(upvote_ratios, bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "            ax.axvline(upvote_ratios.mean(), color='red', linestyle='--', linewidth=2,\n",
    "                        label=f'Mean: {upvote_ratios.mean():.3f}')\n",
    "            ax.axvline(upvote_ratios.median(), color='blue', linestyle='--', linewidth=2,\n",
    "                        label=f'Median: {upvote_ratios.median():.3f}')\n",
    "            ax.set_xlabel('Upvote Ratio')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_title(f'Distribution of Upvote Ratios (n={len(upvote_ratios):,} posts)')\n",
    "            ax.legend()\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Warning: No data available for upvote ratio analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669df45",
   "metadata": {},
   "source": [
    "Ratio se pohybuje od 0 do 1, většinou velmi pozitivní ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35952e01",
   "metadata": {},
   "source": [
    "### 5.7 Integrity and duplicates\n",
    "\n",
    "Najdeme duplicitní ID a další integrity problémy (chybějící ID, extrémně krátké texty, dále taky podmínka a check na NAs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f0eaad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total rows: 1,966\n",
      "  Unique IDs: 1,966\n",
      "  Duplicate IDs: 0 (0.00%)\n",
      "\n",
      "Potential Data Issues:\n",
      "  Warning: Extremely short texts (≤5 chars): 26 rows\n"
     ]
    }
   ],
   "source": [
    "# 5.7 Data Integrity & Duplicates\n",
    "\n",
    "if len(df_unified) > 0:\n",
    "\n",
    "    # Duplicate IDs\n",
    "    if 'id' in df_unified.columns:\n",
    "        total_ids = len(df_unified)\n",
    "        unique_ids = df_unified['id'].nunique()\n",
    "        duplicate_ids = total_ids - unique_ids\n",
    "\n",
    "        print(f\"  Total rows: {total_ids:,}\")\n",
    "        print(f\"  Unique IDs: {unique_ids:,}\")\n",
    "        print(f\"  Duplicate IDs: {duplicate_ids:,} ({duplicate_ids/total_ids*100:.2f}%)\")\n",
    "\n",
    "        if duplicate_ids > 0:\n",
    "            dup_counts = df_unified['id'].value_counts()\n",
    "            most_duplicated = dup_counts[dup_counts > 1].head(5)\n",
    "            print(f\"\\n  Most duplicated IDs:\")\n",
    "            for id_val, count in most_duplicated.items():\n",
    "                print(f\"    {id_val}: appears {count} times\")\n",
    "\n",
    "    # potential issues\n",
    "    print(f\"\\nPotential Data Issues:\")\n",
    "    issues_found = 0\n",
    "\n",
    "    critical_fields = ['id', 'text', 'created_utc']\n",
    "    for field in critical_fields:\n",
    "        if field in df_unified.columns:\n",
    "            na_count = df_unified[field].isna().sum()\n",
    "            if na_count > 0:\n",
    "                print(f\"  Warning {field}: {na_count:,} missing values\")\n",
    "                issues_found += 1\n",
    "\n",
    "    if 'text' in df_unified.columns:\n",
    "        deleted = df_unified['text'].isin(['[deleted]', '[removed]']).sum()\n",
    "        if deleted > 0:\n",
    "            print(f\"  Warning: Deleted/removed content: {deleted:,} rows\")\n",
    "            issues_found += 1\n",
    "\n",
    "    if 'text' in df_unified.columns:\n",
    "        very_short = (df_unified['text'].astype(str).str.len() <= 5).sum()\n",
    "        if very_short > 0:\n",
    "            print(f\"  Warning: Extremely short texts (≤5 chars): {very_short:,} rows\")\n",
    "            issues_found += 1\n",
    "\n",
    "    if issues_found == 0:\n",
    "        print(\"No major data quality issues detected\")\n",
    "\n",
    "else:\n",
    "    print(\"No data available for integrity analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cda4a6",
   "metadata": {},
   "source": [
    "## 6. Data Cleaning\n",
    "\n",
    "Odstraníme smazané a prázdné texty, doplníme nebo ošetříme NA a odfiltrujeme příliš krátké záznamy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "979d1037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 1966 rows\n",
      "    After removing invalid texts: 1923 rows (-43)\n",
      "    After deduplication: 1923 rows\n",
      "    Dropped columns: ['url', 'is_original_content', 'author']\n",
      "  Original rows: 1966\n",
      "  Cleaned rows: 1923\n",
      "  Removed: 43 (2.2%)\n",
      "\n",
      "Data types after cleaning:\n",
      "  post: 999 rows\n",
      "  comment: 924 rows\n",
      "\n",
      "Step 6 complete: 1923 clean rows\n"
     ]
    }
   ],
   "source": [
    "# 6. Data Cleaning: Remove Invalid and Duplicate Content\n",
    "\n",
    "if len(df_unified) > 0:\n",
    "    print(f\"Starting with {len(df_unified)} rows\")\n",
    "\n",
    "    # Step 6a: Remove invalid texts\n",
    "    df_cleaned = drop_invalid_texts(df_unified, min_len=MIN_TEXT_LENGTH)\n",
    "    print(f\"    After removing invalid texts: {len(df_cleaned)} rows (-{len(df_unified) - len(df_cleaned)})\")\n",
    "\n",
    "    # Step 6b: Deduplicate and normalize types\n",
    "    df_cleaned = deduplicate_and_normalize_types(df_cleaned)\n",
    "    print(f\"    After deduplication: {len(df_cleaned)} rows\")\n",
    "\n",
    "    # Step 6c: Droping unnecessary columns (url, is_original_content, author)\n",
    "    columns_to_drop = ['url', 'is_original_content', 'author']\n",
    "    existing_cols_to_drop = [col for col in columns_to_drop if col in df_cleaned.columns]\n",
    "    if existing_cols_to_drop:\n",
    "        df_cleaned.drop(columns=existing_cols_to_drop, inplace=True)\n",
    "        print(f\"    Dropped columns: {existing_cols_to_drop}\")\n",
    "\n",
    "    # Show cleaning results\n",
    "    if len(df_cleaned) > 0:\n",
    "        print(f\"  Original rows: {len(df_unified)}\")\n",
    "        print(f\"  Cleaned rows: {len(df_cleaned)}\")\n",
    "        print(f\"  Removed: {len(df_unified) - len(df_cleaned)} ({((len(df_unified) - len(df_cleaned))/len(df_unified)*100):.1f}%)\")\n",
    "\n",
    "        # Show data types after cleaning\n",
    "        print(f\"\\nData types after cleaning:\")\n",
    "        type_counts = df_cleaned['type'].value_counts()\n",
    "        for dtype, count in type_counts.items():\n",
    "            print(f\"  {dtype}: {count} rows\")\n",
    "    else:\n",
    "        print(\"No data remaining after cleaning.\")\n",
    "\n",
    "else:\n",
    "    print(\"No data to clean\")\n",
    "    df_cleaned = pd.DataFrame()\n",
    "\n",
    "print(f\"\\nStep 6 complete: {len(df_cleaned)} clean rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc0274",
   "metadata": {},
   "source": [
    "## 7. Feature engineering\n",
    "\n",
    "Přidáme užitečné sloupce (text_length, word_count, časové atributy, engagement features). Tyhle featury budeme používat při analýze a modelování."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d42e97b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 'weighted_score' feature (score × upvote_ratio)\n",
      "Dropped columns: ['score', 'upvote_ratio']\n",
      "Enhanced dataframe shape: (1923, 14)\n",
      "\n",
      "New features added: ['date', 'hour', 'day_of_week', 'month', 'is_weekend', 'text_length', 'word_count', 'weighted_score']\n",
      "  Text length: min=11, mean=336.8, max=4194\n",
      "  Word count: min=1, mean=57.2, max=739\n",
      "  Day distribution: {'Saturday': 344, 'Wednesday': 314, 'Sunday': 308, 'Tuesday': 294, 'Friday': 289, 'Monday': 278, 'Thursday': 96}\n",
      "  Weekend posts: 33.9%\n",
      "\n",
      "Step 7 complete: 1923 rows with enhanced features\n"
     ]
    }
   ],
   "source": [
    "# 7. Feature Engineering: Add Temporal and Engagement Features\n",
    "\n",
    "if len(df_cleaned) > 0:\n",
    "    df_features = add_temporal_features(df_cleaned)\n",
    "    df_features = add_engagement_features(df_features)\n",
    "\n",
    "    # Create weighted_score: score × upvote_ratio\n",
    "    if 'score' in df_features.columns and 'upvote_ratio' in df_features.columns:\n",
    "        df_features['weighted_score'] = df_features['score'] * df_features['upvote_ratio']\n",
    "        print(f\"\\nCreated 'weighted_score' feature (score × upvote_ratio)\")\n",
    "\n",
    "    # Drop original score and upvote_ratio columns (we have weighted_score now)\n",
    "    columns_to_drop = ['score', 'upvote_ratio']\n",
    "    existing_cols_to_drop = [col for col in columns_to_drop if col in df_features.columns]\n",
    "    if existing_cols_to_drop:\n",
    "        df_features.drop(columns=existing_cols_to_drop, inplace=True)\n",
    "        print(f\"Dropped columns: {existing_cols_to_drop}\")\n",
    "\n",
    "    print(f\"Enhanced dataframe shape: {df_features.shape}\")\n",
    "\n",
    "    new_features = ['date', 'hour', 'day_of_week', 'month', 'is_weekend',\n",
    "                   'text_length', 'word_count', 'weighted_score']\n",
    "    print(f\"\\nNew features added: {[f for f in new_features if f in df_features.columns]}\")\n",
    "\n",
    "    # Show feature statistics\n",
    "    if 'text_length' in df_features.columns:\n",
    "        print(f\"  Text length: min={df_features['text_length'].min()}, \"\n",
    "              f\"mean={df_features['text_length'].mean():.1f}, \"\n",
    "              f\"max={df_features['text_length'].max()}\")\n",
    "\n",
    "    if 'word_count' in df_features.columns:\n",
    "        print(f\"  Word count: min={df_features['word_count'].min()}, \"\n",
    "              f\"mean={df_features['word_count'].mean():.1f}, \"\n",
    "              f\"max={df_features['word_count'].max()}\")\n",
    "\n",
    "    if 'day_of_week' in df_features.columns:\n",
    "        day_counts = df_features['day_of_week'].value_counts()\n",
    "        print(f\"  Day distribution: {day_counts.to_dict()}\")\n",
    "\n",
    "    if 'is_weekend' in df_features.columns:\n",
    "        weekend_pct = df_features['is_weekend'].mean() * 100\n",
    "        print(f\"  Weekend posts: {weekend_pct:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"No data for feature engineering\")\n",
    "    df_features = pd.DataFrame()\n",
    "\n",
    "print(f\"\\nStep 7 complete: {len(df_features)} rows with enhanced features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65145b",
   "metadata": {},
   "source": [
    "## 8. Ticker detection\n",
    "\n",
    "Detekujeme tickery v textu podle načteného seznamu a uložíme je do `mentioned_tickers` a `n_tickers`. Chceme vědět, o které akcie se mluví v jednotlivých záznamech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06b43a",
   "metadata": {},
   "source": [
    "### 8.1 Identifying Stock Ticker Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18f9518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting tickers in 1923 texts using 8003 symbols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1923/1923 [00:00<00:00, 107658.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total rows: 1923\n",
      "  Rows with tickers: 346 (18.0%)\n",
      "  Rows without tickers: 1577\n",
      "\n",
      "Ticker count distribution:\n",
      "  0 tickers: 1577 rows\n",
      "  1 tickers: 242 rows\n",
      "  2 tickers: 63 rows\n",
      "  3 tickers: 22 rows\n",
      "  4 tickers: 8 rows\n",
      "  5 tickers: 4 rows\n",
      "  6 tickers: 1 rows\n",
      "  7 tickers: 3 rows\n",
      "  12 tickers: 1 rows\n",
      "  14 tickers: 1 rows\n",
      "\n",
      "Step 8 complete: Processed 1923 rows for ticker detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Ticker Detection: Identify Stock Ticker Mentions\n",
    "\n",
    "if len(df_features) > 0 and len(tickers_df) > 0:\n",
    "    print(f\"Detecting tickers in {len(df_features)} texts using {len(tickers_df)} symbols\")\n",
    "\n",
    "    df_with_tickers = apply_ticker_detection(df_features, tickers_df)\n",
    "\n",
    "    # results\n",
    "    ticker_stats = df_with_tickers['n_tickers'].value_counts().sort_index()\n",
    "    total_with_tickers = (df_with_tickers['n_tickers'] > 0).sum()\n",
    "    print(f\"  Total rows: {len(df_with_tickers)}\")\n",
    "    print(f\"  Rows with tickers: {total_with_tickers} ({total_with_tickers/len(df_with_tickers)*100:.1f}%)\")\n",
    "    print(f\"  Rows without tickers: {len(df_with_tickers) - total_with_tickers}\")\n",
    "\n",
    "    print(f\"\\nTicker count distribution:\")\n",
    "    for count, rows in ticker_stats.head(10).items():\n",
    "        print(f\"  {count} tickers: {rows} rows\")\n",
    "\n",
    "else:\n",
    "    print(\"No data or tickers available for detection\")\n",
    "    df_with_tickers = pd.DataFrame()\n",
    "\n",
    "print(f\"\\nStep 8 complete: Processed {len(df_with_tickers)} rows for ticker detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaccec9",
   "metadata": {},
   "source": [
    "### 8.2 Ticker inheritance — Comments inherit parent post tickers\n",
    "\n",
    "Pokud komentář nemá zmíněný ticker, vezmeme tickery z rodičovského postu a spojíme je (union). Tím zlepšíme pokrytí tickerů u komentářů, které odkazují na post bez přesný zmínky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8588d8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recalculated ticker_exchanges after inheritance\n",
      "  Total comments: 924\n",
      "  Comments with tickers (after inheritance): 131\n",
      "  Coverage: 14.2%\n",
      "\n",
      "Step 8.2 completed\n"
     ]
    }
   ],
   "source": [
    "# 8.2 Ticker Inheritance from Parent Posts\n",
    "\n",
    "if len(df_with_tickers) > 0:\n",
    "    posts = df_with_tickers[df_with_tickers['type'] == 'post'].copy()\n",
    "    post_ticker_map = {}\n",
    "\n",
    "    for _, row in posts.iterrows():\n",
    "        post_id = row['id']\n",
    "        tickers_data = row.get('mentioned_tickers', [])\n",
    "\n",
    "        if isinstance(tickers_data, list) and len(tickers_data) > 0:\n",
    "            post_ticker_map[post_id] = set(tickers_data)\n",
    "\n",
    "    def inherit_parent_tickers(row):\n",
    "        if row['type'] == 'comment':\n",
    "            parent_id = row.get('parent_post_id')\n",
    "            if pd.notna(parent_id) and parent_id in post_ticker_map:\n",
    "                own_tickers = set(row.get('mentioned_tickers', []))\n",
    "                parent_tickers = post_ticker_map[parent_id]\n",
    "                merged_tickers = own_tickers.union(parent_tickers)\n",
    "                return sorted(merged_tickers)\n",
    "\n",
    "        tickers_data = row.get('mentioned_tickers', [])\n",
    "        return tickers_data if isinstance(tickers_data, list) else []\n",
    "    df_with_tickers['mentioned_tickers'] = df_with_tickers.apply(inherit_parent_tickers, axis=1)\n",
    "    df_with_tickers['n_tickers'] = df_with_tickers['mentioned_tickers'].apply(len)\n",
    "\n",
    "    # Recalculate ticker_exchanges\n",
    "    ticker_to_exchange = dict(zip(tickers_df[\"ticker\"], tickers_df[\"exchange\"]))\n",
    "\n",
    "    def get_ticker_exchanges_from_list(ticker_list):\n",
    "        \"\"\"Get exchanges for ticker list after inheritance.\"\"\"\n",
    "        if not ticker_list or len(ticker_list) == 0:\n",
    "            return ''\n",
    "\n",
    "        exchanges = set()\n",
    "        for ticker in ticker_list:\n",
    "            exchange = ticker_to_exchange.get(ticker)\n",
    "            if exchange:\n",
    "                exchanges.add(exchange)\n",
    "\n",
    "        if len(exchanges) == 0:\n",
    "            return ''\n",
    "        elif len(exchanges) == 1:\n",
    "            return list(exchanges)[0]\n",
    "        else:\n",
    "            return 'BOTH'\n",
    "\n",
    "    df_with_tickers['ticker_exchanges'] = df_with_tickers['mentioned_tickers'].apply(\n",
    "        get_ticker_exchanges_from_list\n",
    "    )\n",
    "    print(\"  Recalculated ticker_exchanges after inheritance\")\n",
    "\n",
    "    comments = df_with_tickers[df_with_tickers['type'] == 'comment']\n",
    "    comments_with_tickers = comments[comments['n_tickers'] > 0]\n",
    "\n",
    "    print(f\"  Total comments: {len(comments)}\")\n",
    "    print(f\"  Comments with tickers (after inheritance): {len(comments_with_tickers)}\")\n",
    "    if len(comments) > 0:\n",
    "        print(f\"  Coverage: {len(comments_with_tickers) / len(comments) * 100:.1f}%\")\n",
    "    else:\n",
    "        print(f\"  Coverage: N/A (no comments)\")\n",
    "\n",
    "    print(\"\\nStep 8.2 completed\")\n",
    "else:\n",
    "    print(\"No data to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8588d8da",
   "metadata": {},
   "source": [
    "### 8.3 Success check of inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a3481ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments with tickers: 131\n",
      "Comments that inherited tickers: 131\n",
      "Comments that mention tickers explicitly: 0\n",
      "Inheritance success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# 8.3 Ticker Inheritance Examples: Show Cases Where Comments GOT Tickers via Inheritance\n",
    "\n",
    "if len(df_with_tickers) > 0:\n",
    "    comments = df_with_tickers[df_with_tickers['type'] == 'comment'].copy()\n",
    "    comments_with_tickers = comments[comments['n_tickers'] > 0]\n",
    "    comments_with_parents = comments_with_tickers[comments_with_tickers['parent_post_id'].notna()]\n",
    "\n",
    "    def has_ticker_in_text(text, tickers_str):\n",
    "        if not text or not tickers_str:\n",
    "            return False\n",
    "        text_upper = str(text).upper()\n",
    "        ticker_list = str(tickers_str).split(',')\n",
    "\n",
    "        for ticker in ticker_list:\n",
    "            ticker = ticker.strip()\n",
    "            words = text_upper.split()\n",
    "            if ticker in words:\n",
    "                return True\n",
    "            if f\"${ticker}\" in text_upper:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    inherited_only = []\n",
    "    explicit_mention = []\n",
    "\n",
    "    for idx, comment in comments_with_parents.iterrows():\n",
    "        has_explicit = has_ticker_in_text(comment['text'], comment['mentioned_tickers'])\n",
    "\n",
    "        if has_explicit:\n",
    "            explicit_mention.append(comment)\n",
    "        else:\n",
    "            inherited_only.append(comment)\n",
    "    print(f\"Total comments with tickers: {len(comments_with_tickers)}\")\n",
    "    print(f\"Comments that inherited tickers: {len(inherited_only)}\")\n",
    "    print(f\"Comments that mention tickers explicitly: {len(explicit_mention)}\")\n",
    "    print(f\"Inheritance success rate: {len(inherited_only)/len(comments_with_tickers)*100:.1f}%\")\n",
    "else:\n",
    "    print(\"No data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1feef",
   "metadata": {},
   "source": [
    "### 8.4 Data Type Conversion\n",
    "\n",
    "Ensure all columns have the correct data types after feature engineering and ticker detection. This is done here (after Step 8.2) to ensure type conversions persist through the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60357b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types after conversion:\n",
      "  created_utc: datetime64[ns]\n",
      "  date: datetime64[ns]\n",
      "  type: category\n",
      "  subreddit: category\n",
      "  hour: int8\n",
      "  day_of_week: category\n",
      "  is_weekend: bool\n",
      "  text_length: int32\n",
      "  word_count: int32\n",
      "  n_tickers: int16\n",
      "  weighted_score: float32\n"
     ]
    }
   ],
   "source": [
    "# 8.4 Comprehensive Data Type Conversion\n",
    "\n",
    "if len(df_with_tickers) > 0:\n",
    "    # Datetime conversions\n",
    "    df_with_tickers['created_utc'] = pd.to_datetime(df_with_tickers['created_utc'])\n",
    "    df_with_tickers['date'] = pd.to_datetime(df_with_tickers['date'])\n",
    "\n",
    "    # Integer conversions\n",
    "    df_with_tickers['hour'] = df_with_tickers['hour'].astype('int8')\n",
    "    df_with_tickers['month'] = df_with_tickers['month'].astype('int8')\n",
    "    df_with_tickers['text_length'] = df_with_tickers['text_length'].astype('int32')\n",
    "    df_with_tickers['word_count'] = df_with_tickers['word_count'].astype('int32')\n",
    "    df_with_tickers['n_tickers'] = df_with_tickers['n_tickers'].astype('int16')\n",
    "\n",
    "    # Boolean conversions\n",
    "    df_with_tickers['is_weekend'] = df_with_tickers['is_weekend'].astype('bool')\n",
    "\n",
    "    # Category conversions\n",
    "    df_with_tickers['day_of_week'] = df_with_tickers['day_of_week'].astype('category')\n",
    "    df_with_tickers['type'] = df_with_tickers['type'].astype('category')\n",
    "    df_with_tickers['subreddit'] = df_with_tickers['subreddit'].astype('category')\n",
    "\n",
    "    # Float conversions\n",
    "    if 'weighted_score' in df_with_tickers.columns:\n",
    "        df_with_tickers['weighted_score'] = df_with_tickers['weighted_score'].astype('float32')\n",
    "\n",
    "    print(f\"\\nData types after conversion:\")\n",
    "    print(f\"  created_utc: {df_with_tickers['created_utc'].dtype}\")\n",
    "    print(f\"  date: {df_with_tickers['date'].dtype}\")\n",
    "    print(f\"  type: {df_with_tickers['type'].dtype}\")\n",
    "    print(f\"  subreddit: {df_with_tickers['subreddit'].dtype}\")\n",
    "    print(f\"  hour: {df_with_tickers['hour'].dtype}\")\n",
    "    print(f\"  day_of_week: {df_with_tickers['day_of_week'].dtype}\")\n",
    "    print(f\"  is_weekend: {df_with_tickers['is_weekend'].dtype}\")\n",
    "    print(f\"  text_length: {df_with_tickers['text_length'].dtype}\")\n",
    "    print(f\"  word_count: {df_with_tickers['word_count'].dtype}\")\n",
    "    print(f\"  n_tickers: {df_with_tickers['n_tickers'].dtype}\")\n",
    "    if 'weighted_score' in df_with_tickers.columns:\n",
    "        print(f\"  weighted_score: {df_with_tickers['weighted_score'].dtype}\")\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a40c9c",
   "metadata": {},
   "source": [
    "## 9. Text normalization\n",
    "\n",
    "Připravíme text pro sentiment a modely (tokenizace, lemmatizace, odstranění stopwords). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ccc4a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1923/1923 [00:00<00:00, 52972.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using built-in stopword removal (basic)\n",
      "Text normalization complete using Built-in\n",
      "Final dataframe shape: (1923, 18)\n",
      "Final columns: ['created_utc', 'id', 'text', 'subreddit', 'parent_post_id', 'type', 'date', 'hour', 'day_of_week', 'month', 'is_weekend', 'text_length', 'word_count', 'weighted_score', 'mentioned_tickers', 'n_tickers', 'ticker_exchanges', 'sentiment_ready_text']\n",
      "\n",
      "Final dataset statistics:\n",
      "  Total rows: 1923\n",
      "  Rows with tickers: 346\n",
      "  Average original text length: 336.8 characters\n",
      "  Average word count: 57.2 words\n",
      "\n",
      "impact:\n",
      "  Original text length: 336.8 chars\n",
      "  Sentiment-ready text length: 228.9 chars\n",
      "  Reduction from normalization: 32.0%\n",
      "  Stopword removal method: Built-in\n",
      "  Content distribution: {'post': 999, 'comment': 924}\n",
      "\n",
      "Step 9 complete: 1923 rows ready for sentiment analysis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Text Normalization: Prepare Text for Sentiment Analysis\n",
    "# Tickers are already stored in 'mentioned_tickers' column, so we don't need to preserve them in text\n",
    "\n",
    "if len(df_with_tickers) > 0:\n",
    "    df_final = apply_text_normalization(df_with_tickers, keep_tickers=False)\n",
    "    if SPACY_AVAILABLE:\n",
    "        df_final['sentiment_ready_text'] = df_final['sentiment_ready_text'].apply(\n",
    "            lambda x: remove_stopwords_spacy(x, preserve_tickers=False)\n",
    "        )\n",
    "        stopword_method = \"spaCy\"\n",
    "    elif NLTK_AVAILABLE:\n",
    "        print(\"Using NLTK\")\n",
    "        df_final['sentiment_ready_text'] = df_final['sentiment_ready_text'].apply(\n",
    "            lambda x: remove_financial_stopwords(x, preserve_tickers=False)\n",
    "        )\n",
    "        stopword_method = \"NLTK\"\n",
    "    else:\n",
    "        print(\"Using built-in stopword removal (basic)\")\n",
    "        df_final['sentiment_ready_text'] = df_final['sentiment_ready_text'].apply(\n",
    "            lambda x: remove_financial_stopwords(x, preserve_tickers=False)\n",
    "        )\n",
    "        stopword_method = \"Built-in\"\n",
    "\n",
    "    print(f\"Text normalization complete using {stopword_method}\")\n",
    "    print(f\"Final dataframe shape: {df_final.shape}\")\n",
    "    print(f\"Final columns: {list(df_final.columns)}\")\n",
    "\n",
    "    # Final statistics\n",
    "    print(f\"\\nFinal dataset statistics:\")\n",
    "    print(f\"  Total rows: {len(df_final)}\")\n",
    "    print(f\"  Rows with tickers: {(df_final['n_tickers'] > 0).sum()}\")\n",
    "    print(f\"  Average original text length: {df_final['text_length'].mean():.1f} characters\")\n",
    "    print(f\"  Average word count: {df_final['word_count'].mean():.1f} words\")\n",
    "\n",
    "    # Show text processing impact\n",
    "    avg_original_length = df_final['text'].str.len().mean()\n",
    "    avg_sentiment_ready_length = df_final['sentiment_ready_text'].str.len().mean()\n",
    "\n",
    "    print(f\"\\nimpact:\")\n",
    "    print(f\"  Original text length: {avg_original_length:.1f} chars\")\n",
    "    print(f\"  Sentiment-ready text length: {avg_sentiment_ready_length:.1f} chars\")\n",
    "    print(f\"  Reduction from normalization: {((avg_original_length - avg_sentiment_ready_length) / avg_original_length * 100):.1f}%\")\n",
    "    print(f\"  Stopword removal method: {stopword_method}\")\n",
    "\n",
    "    if 'type' in df_final.columns:\n",
    "        type_dist = df_final['type'].value_counts()\n",
    "        print(f\"  Content distribution: {type_dist.to_dict()}\")\n",
    "\n",
    "else:\n",
    "    print(\"No data for text normalization\")\n",
    "    df_final = pd.DataFrame()\n",
    "\n",
    "print(f\"\\nStep 9 complete: {len(df_final)} rows ready for sentiment analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520591c",
   "metadata": {},
   "source": [
    "## 10. Exporting results\n",
    "\n",
    "Uložíme finální dataset s připraveným textem a featurami (CSV). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5320390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: ['created_utc', 'id', 'text', 'subreddit', 'parent_post_id', 'type', 'date', 'hour', 'day_of_week', 'month', 'is_weekend', 'text_length', 'word_count', 'weighted_score', 'mentioned_tickers', 'n_tickers', 'ticker_exchanges', 'sentiment_ready_text']\n",
      "Converted 'mentioned_tickers' from list to comma-separated string format\n",
      "Exported 1923 rows to sentiment_ready_data.csv\n",
      "Exported columns: ['id', 'text', 'sentiment_ready_text', 'type', 'subreddit', 'created_utc', 'weighted_score', 'mentioned_tickers', 'n_tickers', 'ticker_exchanges', 'text_length', 'word_count', 'date', 'hour', 'day_of_week']\n",
      "\n",
      "Exchange distribution (rows with tickers):\n",
      "  NASDAQ: 145 rows\n",
      "  NYSE: 140 rows\n",
      "  BOTH: 61 rows\n",
      "\n",
      "Step 10 complete: Preprocessing pipeline complete.\n"
     ]
    }
   ],
   "source": [
    "# 10. Export Results: Save Sentiment-Ready Data\n",
    "\n",
    "if len(df_final) > 0:\n",
    "    print(f\"Available columns: {list(df_final.columns)}\")\n",
    "\n",
    "    output_file = \"sentiment_ready_data.csv\"\n",
    "\n",
    "    sentiment_columns = [\n",
    "        'id', 'text', 'sentiment_ready_text', 'type', 'subreddit',\n",
    "        'created_utc', 'weighted_score', 'mentioned_tickers', 'n_tickers', 'ticker_exchanges',\n",
    "        'text_length', 'word_count', 'date', 'hour', 'day_of_week']\n",
    "\n",
    "    export_columns = [col for col in sentiment_columns if col in df_final.columns]\n",
    "    export_df = df_final[export_columns].copy()\n",
    "\n",
    "    # Convert mentioned_tickers from list to comma-separated string\n",
    "    if 'mentioned_tickers' in export_df.columns:\n",
    "        export_df['mentioned_tickers'] = export_df['mentioned_tickers'].apply(\n",
    "            lambda x: ','.join(x) if isinstance(x, list) and len(x) > 0 else ''\n",
    "        )\n",
    "        print(f\"Converted 'mentioned_tickers' from list to comma-separated string format\")\n",
    "\n",
    "    export_df.to_csv(output_file, index=False)\n",
    "    print(f\"Exported {len(export_df)} rows to {output_file}\")\n",
    "    print(f\"Exported columns: {export_columns}\")\n",
    "\n",
    "    if 'ticker_exchanges' in export_df.columns:\n",
    "        exchange_dist = export_df[export_df['ticker_exchanges'] != '']['ticker_exchanges'].value_counts()\n",
    "        print(f\"\\nExchange distribution (rows with tickers):\")\n",
    "        for exchange, count in exchange_dist.items():\n",
    "            print(f\"  {exchange}: {count} rows\")\n",
    "\n",
    "else:\n",
    "    print(\"No data to export\")\n",
    "\n",
    "print(f\"\\nStep 10 complete: Preprocessing pipeline complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
