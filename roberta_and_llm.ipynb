{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05435721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]\n",
      "Torch version: 2.7.1+cu118\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from utils import get_oracle_connection\n",
    "import sys\n",
    "print(sys.version)\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eebb41f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle connection successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vitek\\AppData\\Local\\Temp\\ipykernel_12848\\98098836.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment_ready_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_utc",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "normalized_upvotes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mentioned_tickers",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_tickers",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_of_week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "c519130f-0844-4482-8b5e-4227ddf3d7a3",
       "rows": [
        [
         "0",
         "m48hiu4",
         "I'd considering splitting it across two banks in case you need access to funds in a pinch. It's a little more admin and you may get more mailers, but if the access goes down on one of the banks for whatever reason, you still have the other.",
         "comment",
         "investing",
         "2024-12-28 19:22:19",
         "0.018398966640233994",
         "UBS",
         "1",
         "241",
         "47",
         "19",
         "5",
         "2024-12-28 00:00:00"
        ],
        [
         "1",
         "m48hedi",
         "I had the opportunity for the IPO price thing and decided against it lol :/",
         "comment",
         "stocks",
         "2024-12-28 19:21:38",
         "0.011073613539338112",
         "AMD",
         "1",
         "75",
         "15",
         "19",
         "5",
         "2024-12-28 00:00:00"
        ],
        [
         "2",
         "m48heet",
         "Looks like It's down, but the 6 month chart shows so good growth. Sounds good, but hope this trend of going down doesn't persist. Suppose that's the risk factor, could get about 8.6 shares with an initial $200 investment. What broker you use? I'm using Webull, may look Into Fidelity.",
         "comment",
         "investing",
         "2024-12-28 19:21:38",
         "0.018076177686452866",
         "KO",
         "1",
         "286",
         "50",
         "19",
         "5",
         "2024-12-28 00:00:00"
        ],
        [
         "3",
         "m48gxg1",
         "Just look at 52 week lows. Stock screeners will mislead you since they are based on recent metrics. You want to find stocks that people hate and then sort out the ones with long term (not short term) deteriorating financials. You will be left with a few decent ideas. Like $HSY.",
         "comment",
         "ValueInvesting",
         "2024-12-28 19:19:04",
         "0.056502241641283035",
         "HSY",
         "1",
         "278",
         "51",
         "19",
         "5",
         "2024-12-28 00:00:00"
        ],
        [
         "4",
         "m48guco",
         "Are you looking to index? Wealthfront has a new index fund. Fidelity also has one.",
         "comment",
         "investing",
         "2024-12-28 19:18:36",
         "0.018076177686452866",
         "UBS",
         "1",
         "82",
         "15",
         "19",
         "5",
         "2024-12-28 00:00:00"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment_ready_text</th>\n",
       "      <th>type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>normalized_upvotes</th>\n",
       "      <th>mentioned_tickers</th>\n",
       "      <th>n_tickers</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m48hiu4</td>\n",
       "      <td>I'd considering splitting it across two banks ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>investing</td>\n",
       "      <td>2024-12-28 19:22:19</td>\n",
       "      <td>0.018399</td>\n",
       "      <td>UBS</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m48hedi</td>\n",
       "      <td>I had the opportunity for the IPO price thing ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2024-12-28 19:21:38</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>AMD</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m48heet</td>\n",
       "      <td>Looks like It's down, but the 6 month chart sh...</td>\n",
       "      <td>comment</td>\n",
       "      <td>investing</td>\n",
       "      <td>2024-12-28 19:21:38</td>\n",
       "      <td>0.018076</td>\n",
       "      <td>KO</td>\n",
       "      <td>1</td>\n",
       "      <td>286</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m48gxg1</td>\n",
       "      <td>Just look at 52 week lows. Stock screeners wil...</td>\n",
       "      <td>comment</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>2024-12-28 19:19:04</td>\n",
       "      <td>0.056502</td>\n",
       "      <td>HSY</td>\n",
       "      <td>1</td>\n",
       "      <td>278</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m48guco</td>\n",
       "      <td>Are you looking to index? Wealthfront has a ne...</td>\n",
       "      <td>comment</td>\n",
       "      <td>investing</td>\n",
       "      <td>2024-12-28 19:18:36</td>\n",
       "      <td>0.018076</td>\n",
       "      <td>UBS</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-12-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                               sentiment_ready_text     type  \\\n",
       "0  m48hiu4  I'd considering splitting it across two banks ...  comment   \n",
       "1  m48hedi  I had the opportunity for the IPO price thing ...  comment   \n",
       "2  m48heet  Looks like It's down, but the 6 month chart sh...  comment   \n",
       "3  m48gxg1  Just look at 52 week lows. Stock screeners wil...  comment   \n",
       "4  m48guco  Are you looking to index? Wealthfront has a ne...  comment   \n",
       "\n",
       "        subreddit         created_utc  normalized_upvotes mentioned_tickers  \\\n",
       "0       investing 2024-12-28 19:22:19            0.018399               UBS   \n",
       "1          stocks 2024-12-28 19:21:38            0.011074               AMD   \n",
       "2       investing 2024-12-28 19:21:38            0.018076                KO   \n",
       "3  ValueInvesting 2024-12-28 19:19:04            0.056502               HSY   \n",
       "4       investing 2024-12-28 19:18:36            0.018076               UBS   \n",
       "\n",
       "   n_tickers  text_length  word_count  hour  day_of_week       date  \n",
       "0          1          241          47    19            5 2024-12-28  \n",
       "1          1           75          15    19            5 2024-12-28  \n",
       "2          1          286          50    19            5 2024-12-28  \n",
       "3          1          278          51    19            5 2024-12-28  \n",
       "4          1           82          15    19            5 2024-12-28  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = get_oracle_connection()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    ID,\n",
    "    DBMS_LOB.SUBSTR(SENTIMENT_READY_TEXT, 20000, 1) as SENTIMENT_READY_TEXT,\n",
    "    TYPE,\n",
    "    SUBREDDIT,\n",
    "    CREATED_UTC,\n",
    "    NORMALIZED_UPVOTES,\n",
    "    DBMS_LOB.SUBSTR(MENTIONED_TICKERS, 100, 1) as MENTIONED_TICKERS,\n",
    "    N_TICKERS,\n",
    "    TEXT_LENGTH,\n",
    "    WORD_COUNT,\n",
    "    DATE_COL,\n",
    "    HOUR,\n",
    "    DAY_OF_WEEK\n",
    "FROM preprocessed_data\n",
    "FETCH FIRST 1000 ROWS ONLY\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "if 'date_col' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date_col'])\n",
    "    df.drop(columns=['date_col'], inplace=True)\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b762ec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HYBRID SENTIMENT (Notebook B)\n",
      "================================================================================\n",
      "Device: cuda\n",
      "Per-ticker rows: 1,950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Twitter RoBERTa: 100%|██████████| 31/31 [04:49<00:00,  9.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent to LLM: 488 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "LLM:   0%|          | 0/61 [00:00<?, ?it/s]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:   2%|▏         | 1/61 [00:40<40:28, 40.47s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:   3%|▎         | 2/61 [01:17<37:41, 38.33s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:   5%|▍         | 3/61 [01:54<36:35, 37.85s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:   7%|▋         | 4/61 [02:29<34:54, 36.75s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:   8%|▊         | 5/61 [03:04<33:44, 36.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  10%|▉         | 6/61 [04:02<39:58, 43.61s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  11%|█▏        | 7/61 [05:06<45:03, 50.06s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  13%|█▎        | 8/61 [06:07<47:20, 53.59s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  15%|█▍        | 9/61 [06:42<41:32, 47.94s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  16%|█▋        | 10/61 [07:21<38:12, 44.96s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  18%|█▊        | 11/61 [07:59<35:44, 42.90s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  20%|█▉        | 12/61 [08:37<33:46, 41.36s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  21%|██▏       | 13/61 [09:15<32:16, 40.35s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  23%|██▎       | 14/61 [10:03<33:34, 42.87s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  25%|██▍       | 15/61 [10:43<32:08, 41.93s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  26%|██▌       | 16/61 [11:23<30:59, 41.32s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  28%|██▊       | 17/61 [12:11<31:42, 43.25s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  30%|██▉       | 18/61 [12:49<29:50, 41.63s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  31%|███       | 19/61 [13:38<30:48, 44.00s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  33%|███▎      | 20/61 [14:15<28:35, 41.83s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  34%|███▍      | 21/61 [15:02<28:59, 43.50s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  36%|███▌      | 22/61 [15:57<30:23, 46.77s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  38%|███▊      | 23/61 [16:43<29:34, 46.69s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  39%|███▉      | 24/61 [17:18<26:36, 43.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  41%|████      | 25/61 [17:55<24:43, 41.22s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  43%|████▎     | 26/61 [18:36<24:02, 41.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  44%|████▍     | 27/61 [19:13<22:33, 39.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  46%|████▌     | 28/61 [19:58<22:49, 41.51s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  48%|████▊     | 29/61 [20:47<23:16, 43.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  49%|████▉     | 30/61 [21:26<21:51, 42.31s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  51%|█████     | 31/61 [22:17<22:25, 44.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  52%|█████▏    | 32/61 [22:58<21:09, 43.76s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  54%|█████▍    | 33/61 [24:03<23:26, 50.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  56%|█████▌    | 34/61 [24:50<22:06, 49.14s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  57%|█████▋    | 35/61 [25:55<23:23, 53.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  59%|█████▉    | 36/61 [27:00<23:55, 57.41s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  61%|██████    | 37/61 [27:46<21:32, 53.84s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  62%|██████▏   | 38/61 [28:31<19:35, 51.10s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  64%|██████▍   | 39/61 [29:13<17:47, 48.51s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  66%|██████▌   | 40/61 [30:10<17:52, 51.05s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  67%|██████▋   | 41/61 [30:55<16:23, 49.19s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  69%|██████▉   | 42/61 [31:28<14:04, 44.44s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  70%|███████   | 43/61 [32:06<12:42, 42.38s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  72%|███████▏  | 44/61 [32:43<11:35, 40.92s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  74%|███████▍  | 45/61 [33:17<10:19, 38.75s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  75%|███████▌  | 46/61 [33:51<09:17, 37.16s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  77%|███████▋  | 47/61 [34:32<08:57, 38.41s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  79%|███████▊  | 48/61 [35:10<08:18, 38.32s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  80%|████████  | 49/61 [35:45<07:26, 37.23s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  82%|████████▏ | 50/61 [36:18<06:36, 36.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  84%|████████▎ | 51/61 [36:57<06:10, 37.03s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  85%|████████▌ | 52/61 [37:31<05:23, 35.99s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  87%|████████▋ | 53/61 [38:09<04:53, 36.65s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  89%|████████▊ | 54/61 [38:49<04:22, 37.50s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  90%|█████████ | 55/61 [39:46<04:20, 43.49s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  92%|█████████▏| 56/61 [40:43<03:58, 47.67s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  93%|█████████▎| 57/61 [41:18<02:54, 43.74s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  95%|█████████▌| 58/61 [41:57<02:07, 42.41s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  97%|█████████▋| 59/61 [42:31<01:19, 39.80s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM:  98%|█████████▊| 60/61 [43:28<00:45, 45.07s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "LLM: 100%|██████████| 61/61 [44:26<00:00, 43.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to sentiment_hybrid_twitter_llm.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\vitek\\AppData\\Local\\Temp\\ipykernel_12848\\3971707296.py:249: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df_llm.index, \"llm_sentiment_label\"] = df_llm[\"llm_sentiment_label\"]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "HYBRID SENTIMENT PIPELINE (Notebook B)\n",
    "\n",
    "Assumes:\n",
    "- df is ALREADY loaded in a previous cell from Oracle\n",
    "- df columns are already lowercase\n",
    "\n",
    "Pipeline:\n",
    "1) Twitter RoBERTa sentiment per (text, ticker) for ALL rows.\n",
    "2) Local instruction LLM (Qwen) only for uncertain cases where\n",
    "   tw_score ∈ [-0.1, +0.1].\n",
    "3) Produces:\n",
    "   tw_score, tw_label\n",
    "   llm_sentiment_score, llm_sentiment_label\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIG\n",
    "# ============================================================================\n",
    "\n",
    "OUTPUT_FILE = \"sentiment_hybrid_twitter_llm.csv\"\n",
    "\n",
    "TEXT_COL   = \"sentiment_ready_text\"\n",
    "TICKER_COL = \"mentioned_tickers\"\n",
    "\n",
    "TW_MODEL_NAME  = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "LLM_MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "BATCH_SIZE_CLS = 64\n",
    "BATCH_SIZE_LLM = 8\n",
    "\n",
    "MAX_INPUT_TOKENS = 512\n",
    "MAX_NEW_TOKENS   = 64\n",
    "USE_FP16_LLM = True\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HYBRID SENTIMENT (Notebook B)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# DEVICE\n",
    "# ============================================================================\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ============================================================================\n",
    "# BASIC PREP (df already exists)\n",
    "# ============================================================================\n",
    "\n",
    "def parse_tickers(x):\n",
    "    if pd.isna(x) or x == \"\":\n",
    "        return []\n",
    "    try:\n",
    "        return [str(t).strip() for t in ast.literal_eval(str(x)) if t]\n",
    "    except:\n",
    "        return [t.strip() for t in str(x).split(\",\") if t.strip()]\n",
    "\n",
    "df[\"tickers_list\"] = df[TICKER_COL].apply(parse_tickers)\n",
    "df[\"n_tickers\"] = df[\"tickers_list\"].apply(len)\n",
    "\n",
    "df = df[df[\"n_tickers\"] > 0].copy()\n",
    "\n",
    "# Explode to per-ticker rows\n",
    "df = df.explode(\"tickers_list\").reset_index(drop=True)\n",
    "df = df.rename(columns={\"tickers_list\": \"ticker\"})\n",
    "\n",
    "print(f\"Per-ticker rows: {len(df):,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD TWITTER ROBERTA\n",
    "# ============================================================================\n",
    "\n",
    "tw_tokenizer = AutoTokenizer.from_pretrained(TW_MODEL_NAME)\n",
    "tw_model     = AutoModelForSequenceClassification.from_pretrained(TW_MODEL_NAME)\n",
    "tw_model.to(device)\n",
    "tw_model.eval()\n",
    "\n",
    "# ============================================================================\n",
    "# TWITTER ROBERTA FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def twitter_batch(texts, tickers):\n",
    "    texts = [f\"{tic}: {txt}\" for txt, tic in zip(texts, tickers)]\n",
    "\n",
    "    enc = tw_tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_INPUT_TOKENS,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs = torch.softmax(tw_model(**enc).logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    id2label = tw_model.config.id2label\n",
    "    results = []\n",
    "\n",
    "    for prob in probs:\n",
    "        p_pos = prob[list(id2label.values()).index(\"positive\")]\n",
    "        p_neg = prob[list(id2label.values()).index(\"negative\")]\n",
    "\n",
    "        score = p_pos - p_neg\n",
    "\n",
    "        if score > 0.15:\n",
    "            label = \"positive\"\n",
    "        elif score < -0.15:\n",
    "            label = \"negative\"\n",
    "        else:\n",
    "            label = \"neutral\"\n",
    "\n",
    "        results.append((score, label))\n",
    "\n",
    "    return results\n",
    "\n",
    "# ============================================================================\n",
    "# RUN TWITTER ROBERTA\n",
    "# ============================================================================\n",
    "\n",
    "tw_scores = []\n",
    "tw_labels = []\n",
    "\n",
    "texts = df[TEXT_COL].fillna(\"\").tolist()\n",
    "tickers = df[\"ticker\"].tolist()\n",
    "\n",
    "for i in tqdm(range(0, len(texts), BATCH_SIZE_CLS), desc=\"Twitter RoBERTa\"):\n",
    "    batch_texts = texts[i:i+BATCH_SIZE_CLS]\n",
    "    batch_tickers = tickers[i:i+BATCH_SIZE_CLS]\n",
    "    res = twitter_batch(batch_texts, batch_tickers)\n",
    "    for s,l in res:\n",
    "        tw_scores.append(s)\n",
    "        tw_labels.append(l)\n",
    "\n",
    "df[\"tw_score\"] = tw_scores\n",
    "df[\"tw_label\"] = tw_labels\n",
    "\n",
    "# ============================================================================\n",
    "# SELECT UNCERTAIN FOR LLM (tw_score between -0.1 and 0.1)\n",
    "# ============================================================================\n",
    "\n",
    "df_llm = df[df[\"tw_score\"].between(-0.1, 0.1)].copy()\n",
    "print(f\"Sent to LLM: {len(df_llm):,} rows\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD QWEN LLM\n",
    "# ============================================================================\n",
    "\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLM_MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if device==\"cuda\" else None,\n",
    "    device_map=\"auto\" if device==\"cuda\" else None\n",
    ")\n",
    "\n",
    "llm_model.eval()\n",
    "\n",
    "if llm_tokenizer.pad_token is None:\n",
    "    llm_tokenizer.pad_token = llm_tokenizer.eos_token\n",
    "\n",
    "# ============================================================================\n",
    "# FEW-SHOT PROMPT\n",
    "# ============================================================================\n",
    "\n",
    "def build_prompt(text, ticker):\n",
    "    return f\"\"\"\n",
    "You are a financial sentiment analyst.\n",
    "\n",
    "Examples:\n",
    "Comment: NVDA is a disaster, terrible performance.\n",
    "Result: {{\"ticker\":\"NVDA\",\"label\":\"negative\",\"score\":-0.8}}\n",
    "\n",
    "Comment: TSLA looks okay, maybe sideways.\n",
    "Result: {{\"ticker\":\"TSLA\",\"label\":\"neutral\",\"score\":0.0}}\n",
    "\n",
    "Comment: AAPL to the moon!!!\n",
    "Result: {{\"ticker\":\"AAPL\",\"label\":\"positive\",\"score\":0.8}}\n",
    "\n",
    "Now analyze:\n",
    "\n",
    "Ticker: {ticker}\n",
    "Comment: {text}\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "\"\"\"\n",
    "\n",
    "def parse_llm(text):\n",
    "    m = re.search(r\"\\{.*\\}\", text)\n",
    "    if not m:\n",
    "        return \"neutral\", 0.0\n",
    "    try:\n",
    "        d = json.loads(m.group())\n",
    "        return d.get(\"label\",\"neutral\"), float(d.get(\"score\",0.0))\n",
    "    except:\n",
    "        return \"neutral\", 0.0\n",
    "\n",
    "def run_llm_batch(texts, tickers):\n",
    "    prompts = [build_prompt(t, tic) for t, tic in zip(texts, tickers)]\n",
    "\n",
    "    inputs = llm_tokenizer(prompts, return_tensors=\"pt\",\n",
    "                           padding=True, truncation=True,\n",
    "                           max_length=MAX_INPUT_TOKENS).to(device)\n",
    "\n",
    "    outputs = llm_model.generate(**inputs, max_new_tokens=MAX_NEW_TOKENS)\n",
    "    decoded = llm_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return [parse_llm(o) for o in decoded]\n",
    "\n",
    "# ============================================================================\n",
    "# RUN LLM\n",
    "# ============================================================================\n",
    "\n",
    "llm_labels = []\n",
    "llm_scores = []\n",
    "\n",
    "texts_llm = df_llm[TEXT_COL].tolist()\n",
    "tickers_llm = df_llm[\"ticker\"].tolist()\n",
    "\n",
    "for i in tqdm(range(0, len(texts_llm), BATCH_SIZE_LLM), desc=\"LLM\"):\n",
    "    batch_texts = texts_llm[i:i+BATCH_SIZE_LLM]\n",
    "    batch_tickers = tickers_llm[i:i+BATCH_SIZE_LLM]\n",
    "    res = run_llm_batch(batch_texts, batch_tickers)\n",
    "\n",
    "    for l,s in res:\n",
    "        llm_labels.append(l)\n",
    "        llm_scores.append(s)\n",
    "\n",
    "df_llm[\"llm_sentiment_label\"] = llm_labels\n",
    "df_llm[\"llm_sentiment_score\"] = llm_scores\n",
    "\n",
    "# Merge back\n",
    "df[\"llm_sentiment_label\"] = np.nan\n",
    "df[\"llm_sentiment_score\"] = np.nan\n",
    "\n",
    "df.loc[df_llm.index, \"llm_sentiment_label\"] = df_llm[\"llm_sentiment_label\"]\n",
    "df.loc[df_llm.index, \"llm_sentiment_score\"] = df_llm[\"llm_sentiment_score\"]\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE\n",
    "# ============================================================================\n",
    "\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(\"✅ Saved to\", OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ee3b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment_ready_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_utc",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "normalized_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mentioned_tickers",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_tickers",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_of_week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ticker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tw_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tw_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tw_p_positive",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tw_p_neutral",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tw_p_negative",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_sentiment_label",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_sentiment_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f73f4ec3-2110-476c-a880-f77fa2a9b191",
       "rows": [
        [
         "0",
         "1hqr72t",
         "What is a good ROE? (Return on Equity) - Quick Data Analysis. It’s often said that a ROE > 15% sustained over time can indicate quality, but… what do the actual data say? Data: * Average ROE: **6.3%** * Median ROE: **9.6%** * Percentile 25 (P25): **1.1%** * Percentile 75 (P75): **16.6%** Universe analyzed: * Over 100,000 data points. * Filtered between percentiles 5 and 95 (outliers excluded). * Primarily U.S. companies across all sectors. Quick takeaway: A ROE > 15% sits around the **71st percentile**, meaning any company with a higher ROE falls within the **TOP 30%** for return on equity. The popular belief seems to hold, but… Caution: **A high ROE doesn’t always indicate quality**. It can be misleading due to: • High leverage: greater financial risk. • Debt structures or non-recurring income. • Sector-specific variations: some industries naturally have higher or lower ROEs. At the end of the day, business quality isn’t just about one number. What do you think? Any other metrics you’d like to see analyzed?",
         "post",
         "investing",
         "2024-12-31 23:56:46",
         "0.019044545",
         "TOP",
         "1",
         "1072",
         "171",
         "2024-12-31",
         "23",
         "1",
         "TOP",
         "0.1005377620458602",
         "neutral",
         "0.133484661579132",
         "0.8335684537887573",
         "0.0329468995332717",
         null,
         null
        ],
        [
         "1",
         "1hqqmq2",
         "Soundhound ($SOUN) now has a market cap 75x it’s annualized revenue…. It was overvalued a couple months ago and now things are getting especially wild. On top of that, most of it’s year-on-year revenue growth is inorganic and will come back down to earth in a couple quarters. I haven’t shorted yet because I believe there will be more market wide irrational pumps in Q1/Q2 2025…but I absolutely will short big time in H1 of next year when sentiment is particularly bullish.",
         "post",
         "stocks",
         "2024-12-31 23:24:29",
         "0.039443154",
         "SOUN",
         "1",
         "476",
         "82",
         "2024-12-31",
         "23",
         "1",
         "SOUN",
         "-0.3443237468600273",
         "negative",
         "0.0834576860070228",
         "0.4887608885765075",
         "0.4277814328670501",
         null,
         null
        ],
        [
         "2",
         "1hqqgv5",
         "Is $SMCI beginning to be a play?. P/E is looking rather low, current valuation is at about fair value. Peak this year was about 4x the current price. Earnings are solid. Would be nice to see the Q4 results to be fair... Delisting was given an exception until the 25th of February, if all goes well with that it seems there's no reason to continue a downtrend other than normal market conditions... Anything I'm missing?",
         "post",
         "stocks",
         "2024-12-31 23:15:10",
         "0.011073614",
         "SMCI",
         "1",
         "419",
         "75",
         "2024-12-31",
         "23",
         "1",
         "SMCI",
         "0.7040771059691906",
         "positive",
         "0.7273244857788086",
         "0.2494281232357025",
         "0.0232473798096179",
         null,
         null
        ],
        [
         "3",
         "1hqpxkb",
         "Any thoughts on RDDT feedback appreciated.",
         "post",
         "investing",
         "2024-12-31 22:45:36",
         "0.018076178",
         "RDDT",
         "1",
         "42",
         "6",
         "2024-12-31",
         "22",
         "1",
         "RDDT",
         "0.0801958460360765",
         "neutral",
         "0.1001332625746727",
         "0.8799293041229248",
         "0.0199374165385961",
         null,
         null
        ],
        [
         "4",
         "1hqpw3r",
         "Is D.R.Horton (DHI) good value ?. The stock is down almost 7% YTD & with a forward PE of 9 it looks relatively fair priced. Also has a nice dividend yield of 1.1% - We are always going to be needing new homes & improved homes so its a pretty recession proofed business. Might dollar cost average into it only because I believe it's a fair price for a great business. What are your thoughts?",
         "post",
         "ValueInvesting",
         "2024-12-31 22:43:25",
         "0.051121075",
         "DHI",
         "1",
         "391",
         "75",
         "2024-12-31",
         "22",
         "1",
         "DHI",
         "0.6598160397261381",
         "positive",
         "0.6863262057304382",
         "0.2871636748313904",
         "0.0265101660043001",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment_ready_text</th>\n",
       "      <th>type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>mentioned_tickers</th>\n",
       "      <th>n_tickers</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>ticker</th>\n",
       "      <th>tw_score</th>\n",
       "      <th>tw_label</th>\n",
       "      <th>tw_p_positive</th>\n",
       "      <th>tw_p_neutral</th>\n",
       "      <th>tw_p_negative</th>\n",
       "      <th>llm_sentiment_label</th>\n",
       "      <th>llm_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1hqr72t</td>\n",
       "      <td>What is a good ROE? (Return on Equity) - Quick...</td>\n",
       "      <td>post</td>\n",
       "      <td>investing</td>\n",
       "      <td>2024-12-31 23:56:46</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>TOP</td>\n",
       "      <td>1</td>\n",
       "      <td>1072</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>TOP</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.133485</td>\n",
       "      <td>0.833568</td>\n",
       "      <td>0.032947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1hqqmq2</td>\n",
       "      <td>Soundhound ($SOUN) now has a market cap 75x it...</td>\n",
       "      <td>post</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2024-12-31 23:24:29</td>\n",
       "      <td>0.039443</td>\n",
       "      <td>SOUN</td>\n",
       "      <td>1</td>\n",
       "      <td>476</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>SOUN</td>\n",
       "      <td>-0.344324</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.083458</td>\n",
       "      <td>0.488761</td>\n",
       "      <td>0.427781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1hqqgv5</td>\n",
       "      <td>Is $SMCI beginning to be a play?. P/E is looki...</td>\n",
       "      <td>post</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2024-12-31 23:15:10</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>SMCI</td>\n",
       "      <td>1</td>\n",
       "      <td>419</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>SMCI</td>\n",
       "      <td>0.704077</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.727324</td>\n",
       "      <td>0.249428</td>\n",
       "      <td>0.023247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1hqpxkb</td>\n",
       "      <td>Any thoughts on RDDT feedback appreciated.</td>\n",
       "      <td>post</td>\n",
       "      <td>investing</td>\n",
       "      <td>2024-12-31 22:45:36</td>\n",
       "      <td>0.018076</td>\n",
       "      <td>RDDT</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>RDDT</td>\n",
       "      <td>0.080196</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.100133</td>\n",
       "      <td>0.879929</td>\n",
       "      <td>0.019937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1hqpw3r</td>\n",
       "      <td>Is D.R.Horton (DHI) good value ?. The stock is...</td>\n",
       "      <td>post</td>\n",
       "      <td>ValueInvesting</td>\n",
       "      <td>2024-12-31 22:43:25</td>\n",
       "      <td>0.051121</td>\n",
       "      <td>DHI</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>DHI</td>\n",
       "      <td>0.659816</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.686326</td>\n",
       "      <td>0.287164</td>\n",
       "      <td>0.026510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                               sentiment_ready_text  type  \\\n",
       "0  1hqr72t  What is a good ROE? (Return on Equity) - Quick...  post   \n",
       "1  1hqqmq2  Soundhound ($SOUN) now has a market cap 75x it...  post   \n",
       "2  1hqqgv5  Is $SMCI beginning to be a play?. P/E is looki...  post   \n",
       "3  1hqpxkb         Any thoughts on RDDT feedback appreciated.  post   \n",
       "4  1hqpw3r  Is D.R.Horton (DHI) good value ?. The stock is...  post   \n",
       "\n",
       "        subreddit          created_utc  normalized_score mentioned_tickers  \\\n",
       "0       investing  2024-12-31 23:56:46          0.019045               TOP   \n",
       "1          stocks  2024-12-31 23:24:29          0.039443              SOUN   \n",
       "2          stocks  2024-12-31 23:15:10          0.011074              SMCI   \n",
       "3       investing  2024-12-31 22:45:36          0.018076              RDDT   \n",
       "4  ValueInvesting  2024-12-31 22:43:25          0.051121               DHI   \n",
       "\n",
       "   n_tickers  text_length  word_count  ... hour  day_of_week  ticker  \\\n",
       "0          1         1072         171  ...   23            1     TOP   \n",
       "1          1          476          82  ...   23            1    SOUN   \n",
       "2          1          419          75  ...   23            1    SMCI   \n",
       "3          1           42           6  ...   22            1    RDDT   \n",
       "4          1          391          75  ...   22            1     DHI   \n",
       "\n",
       "   tw_score  tw_label tw_p_positive  tw_p_neutral  tw_p_negative  \\\n",
       "0  0.100538   neutral      0.133485      0.833568       0.032947   \n",
       "1 -0.344324  negative      0.083458      0.488761       0.427781   \n",
       "2  0.704077  positive      0.727324      0.249428       0.023247   \n",
       "3  0.080196   neutral      0.100133      0.879929       0.019937   \n",
       "4  0.659816  positive      0.686326      0.287164       0.026510   \n",
       "\n",
       "   llm_sentiment_label llm_sentiment_score  \n",
       "0                  NaN                 NaN  \n",
       "1                  NaN                 NaN  \n",
       "2                  NaN                 NaN  \n",
       "3                  NaN                 NaN  \n",
       "4                  NaN                 NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80b9d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]\n",
      "Torch version: 2.7.1+cu118\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
